[{"title":"Hello World","url":"/2022/01/09/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n"},{"title":"text","url":"/2022/02/05/text/","content":"测试测试测试\n","categories":["操作系统"],"tags":["内存分配"]},{"title":"第三章 物理内存分配","url":"/2022/02/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter3%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","content":"第三章 物理内存分配3.1 计算机体系结构及内存分层体系计算机体系结构计算机组成原理\nCPU，内存，总线，I/O\n内存体系结构OS内存管理目标\n抽象（逻辑地址空间）：应用程序不需要考虑底层细节\n保护（独立地址空间）：内存中可以运行多个应用程序，多个程序可能访问别的程序的地址空间或者破坏其他程序\n共享（访问相同内存）：进程之间安全有效可靠的数据传递\n虚拟化（更多的地址空间）：当内存不够时，把最需要的数据放在内存中，暂时不需要访问的数据可以临时的放到硬盘上\n\nOS内存管理方法\n程序重定位\n分段\n分页\n虚拟内存\n按需分页虚拟内存\n\n实现高度依赖于硬件\n\nMMU（内存管理单元）：硬件组件负责处理CPU的内存访问请求\n\n3.2 地址空间与地址生成地址空间物理地址空间——硬件支持的地址空间（起始0，MAX_sys）\n逻辑地址空间——一个运行的程序所拥有的的内存范围（0，MAX_prog）\n逻辑地址的生成\n\n物理地址的生成\n\n\n地址安全检查\n\n3.3 连续内存分配内存碎片内存碎片问题指的是空闲的内存无法被利用\n\n外部碎片：分配单元之间的未使用内存\n内部碎片 :  分配给应用程序的单元内的未使用内存\n\n分区的动态分配\n第一匹配分配：在内存中找到第一个比需求大的空闲块, 分配给应用程序\n\n\n\n\n分配方式\n第一匹配分配\n最优适配分配\n最差适配分配\n\n\n\n实现需求\n1. 按地址排序的空闲块列表2. 分配需要寻找一个合适的分区3. 重分配需要检查是否可以合并相邻空闲分区\n1. 按尺寸排序的空闲块列表2. 分配需要寻找一个合适的分区3. 重分配需要检查是否可以合并相邻空闲分区\n1. 按尺寸排序的空闲块列表2. 分配最大的分区3. 重分配需要检查是否可以合并相邻空闲分区\n\n\n优势\n简单 / 易于产生更大空闲块\n比较简单 / 大部分分配是小尺寸时有效\n分配很快 / 大部分分配是中尺寸时高效\n\n\n劣势\n产生外部碎片 / 不确定性\n产生外部碎片 / 重分配慢 / 易产生很多没用的微小碎片\n产生外部碎片 / 重分配慢 / 易于破碎大的空闲块以致大分区无法被分配\n\n\n3.4 连续内存分配：压缩式与交换式碎片整理无论使用那种算法，都可能产生碎片，希望想有一些办法使得碎片减少甚至消失\n压缩式碎片整理\n重置程序以合并空洞\n要求所有程序是动态可充值的\n议题\n何时重置？\n开销\n\n\n\n\n通过拷贝完成（重定位）\n在运行的时候挪操作，地址会不对\n\n应在程序停止时进行\n\n开销很大，甚至可能影响整个系统的正常执行\n\n\n交换式碎片整理\n运行程序需要更多的内存\n抢占等待的程序&amp;回收他们的内存(把暂时不用的内容挪到磁盘里)\n议题：哪些程序应该被抢占以及什么时候执行\n\n\n操作系统内核特征\n\n并发：计算机系统中同时存在多个运行的程序，需要OS管理和调度\n共享：宏观上“同时访问”，微观上互斥共享\n虚拟：利用多到程序设计技术，让每个用户都觉得有一个计算机专门为他服务\n异步：程序的执行不是一贯到底，而是走走停停，向前推进的速度不可预知，只要运行环境相同，OS需要保证程序运行的结果也要相同\n\n","categories":["操作系统"],"tags":["内存分配"]},{"title":"第五章 虚拟内存","url":"/2021/02/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter5%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/","content":"第五章 虚拟内存5.1 起因程序规模的增长远大于存储器容量发展的速度，让更多的程序跑在有限的内存里面\n使用硬盘/磁盘使更多的程序在有限的内存中运行\n理想的存储器：\n更大，更快，更便宜的非易失性存储器\n实际中的存储器：\n\n5.2 覆盖技术目标：是在较小的可用内存中运行较大的程序, 常用于多道程序系统, 与分区存储管理配合使用\n原理：\n\n把程序按照其自身逻辑结构, 划分为若干个功能上相互独立的程序模块, 那些不会同时执行的模块共享同一块内存区域, 按时间先后来运行\n必要部分(常用功能)的代码和数据常驻内存\n可选部分(不常用功能)在其他程序模块中实现, 平时存放在外存中, 在需要用到时才装入内存\n不存在调用关系的模块不必同时装入到内存, 从而可以相互覆盖, 即这些模块共用一个分区\n\n\n\n\n\n缺点：\n由程序员来把一个大的程序划分为若干个小的功能模块, 并确定各个模块之间的覆盖关系, 费时费力, 增加了编程的复杂度\n覆盖模块并从外存装入内存, 实际上是以时间延长来换取空间节省\n\n\n\n5.3 交换技术如果是程序太多, 超过了内存的容量, 可以采用自动的交换(swapping)技术, 把暂时不能执行的程序送到外存中\n目标：\n\n多道程序在内存时, 让正在运行的程序或需要运行的程序获得更多的内存资源\n\n方法：\n\n可将暂时不能运行的程序送到外存, 从而获得空闲内存空间\n操作系统把一个进程的整个地址空间的内容保存到外存中(换出 swap out), 而将外存中的某个进程的地址空间读入到内存中(换入 swap in). 换入换出内容的大小为整个程序的地址空间\n\n交换技术实现中的几个问题：\n\n交换时机的确定 : 何时需要发生交换? 只当内存空间不够或有不够的危险时换出\n交换区的大小 : 必须足够大以存放所有用户进程的所有内存映像的拷贝, 必须能够对这些内存映像进行直接存取\n程序换入时的重定位 : 换出后再换入的内存位置一定要在原来的位置上嘛?(可能出现寻址问题) 最好采用动态地址映射的方法\n\n覆盖与交换的比较\n\n覆盖只能发生在那些相互之间没有调用关系的程序模块之间, 因此程序员必须给出程序内的各个模块之间的逻辑覆盖结构\n交换技术是以在内存中的程序大小为单位进行的, 它不需要程序员给出各个模块之间的逻辑覆盖结构。换言之, 交换发生在内存中程序与管理程序或操作系统之间, 而覆盖则发生在运行程序的内部\n\n5.4 虚存技术在内存不够用的情形下, 可以采用覆盖技术和交换技术, 但是 :\n\n覆盖技术 : 需要程序要自己把整个程序划分为若干个小的功能模块, 并确定各个模块之间的覆盖关系, 增加了程序员的负担\n交换技术 : 以进程作为交换的单位, 需要把进程的整个地址空间都换入换出, 增加了处理器的开销\n\n目标：\n\n像覆盖技术那样, 不是把程序的所有内容都放在内存中, 因而能够运行比当前的空闲内存空间还要大的程序. 但做的更好, 由操作系统自动来完成, 无需程序员的干涉\n像交换技术那样, 能够实现进程在内存与外存之间的交换, 因而获得更多的空闲内存空间. 但做的更好, 只对进程的部分内容在内存和外存之间进行交换\n以更小的页粒度为单位装入更多更大的程序\n\n程序的局部性原理\n\n程序的局部性原理(principle of locality) : 指程序在执行过程中的一个较短时期, 所执行的指令地址和指令的操作数地址, 分别局限于一定的区域\n时间局部性 : 一条指令的一次执行和下次执行, 一个数据的一次访问和下次访问都集中在一个较短时期内\n空间局部性 : 当前指令和邻近的几条指令, 当前访问的数据和邻近的几个数据都集中在一个较小区域内\n\n\n\n程序的局部性原理表明, 从理论上来说, 虚拟存储技术是能够实现的. 而且在实现了以后应该是能够取得一个满意的效果\n实例：\n页面大小为4k, 分配给每个进程的物理页面是1. 在一个进程中, 定义了如下的二维数组 int A[1024][1024]. 该数组按行存放在内存, 每一行放在一个页面中.考虑一下程序的编写方法对缺页率的影响?程序编写方法1 : (发生了1024*1024次缺页中断)for(j = 0; j &lt; 1024; j++)\t\tfor(i = 0; i &lt; 1024; i++)\t\t\t\tA[i][j] = 0;程序编写方法2 : (发生了1024次缺页中断)for(i = 0; i &lt; 1024; i++)\t\tfor(j = 0; j &lt; 1024; j++)\t\t\t\tA[i][j] = 0;\n\n基本概念\n可以在页式或段式内存管理的基础上实现\n\n在装入程序时, 不必将其全部装入内存, 而只需将当前需要执行的部分页面或段装入到内存中, 就可以让程序开始执行\n在程序执行过程中, 如果需执行的指令或访问的数据尚未在内存中(称为缺页或缺段), 则由处理器通知操作系统将相应的页面或段调入到内存, 然后继续执行程序\n另一方面, 操作系统将内存中暂时不使用的页面或段调出保存在外存上, 从而腾出更多空闲内存空间存放将要装入的程序以及将要调入的页面或段\n\n基本特征\n\n大的用户空间 : 通过把物理内存和外存相结合, 提供给用户的虚拟内存空间通常大于实际的物理内存, 即实现了这两者的分离. 如32位的虚拟地址理论上可以访问4GB, 而可能计算机上仅有256M的物理内存, 但硬盘容量大于4GB\n部分交换 : 与交换技术相比较, 虚拟存储的调入和调出是对部分虚拟地址空间进行的\n不连续性 : 物理内存分配的不连续性, 虚拟地址空间使用的不连续性\n\n页式内存管理页表 : 完成逻辑页到物理页帧的映射\n根据页号去页表中寻找索引, 先查看 resident bit 是否为0, 0表示不存在, 1表示映射关系存在, 获得帧号加上原本的偏移, 获得了物理地址\n虚拟页式内存管理\n\n大部分虚拟存储系统都采用虚拟页式存储管理技术, 即在页式存储管理的基础上, 增加请求调页和页面置换功能\n\n基本思路\n\n当一个用户程序要调入内存运行时, 不是将该程序的所有页面都装入内存, 而是只装入部分的页面, 就可启动程序运行.\n在运行的过程中, 如果发现要运行的程序或要访问的数据不再内存, 则向系统发出缺页的中断请求, 系统在处理这个中断时, 将外存中相应的页面调入内存, 使得该程序能够继续运行\n\n\n页表表项\n\n驻留位 : 表示该页是在内存中还是在外存\n保护位 : 表示允许对该页做何种类型的访问, 如只读, 可读写, 可执行等\n修改位 : 表示此页在内存中是否被修改过. 当系统回收该物理页面时, 根据此位来决定是否把它的内容写回外存\n访问位 : 如果该页被访问过(包括读写操作), 则设置此位. 用于页面置换算法\n\n\n缺页中断处理过程\n\n如果在内存中有空闲的物理页面, 则分配一物理页帧f, 然后转第4步; 否则转到第2步\n采用某种页面置换算法, 选择一个将被替换的物理页帧f, 它所对应的逻辑页为q, 如果该页在内存期间被修改过, 则需要把它写回外存\n对q所对应的页表项修改, 把驻留位置为0\n将需要访问的页p装入到物理页面f当中\n修改p所对应的页表项的内容, 把驻留位置为1, 把物理页帧号置为f\n重新运行被中断是指令\n\n\n\n在何处保存未被映射的页？\n\n能够简单地识别在二级存储器中的页\n交换空间(磁盘或者文件) : 特殊格式, 用于存储未被映射的页面\n\n后备存储 backing store（二级存储）\n一个虚拟地址空间的页面可以被映射到一个文件(在二级存储中)的某个位置\n代码段 : 映射到可执行二进制文件\n动态加载的共享库程序段 : 映射到动态调用的库文件\n其他段 : 可能被映射到交换文件(swap file)\n\n虚拟内存性能为了便于理解分页的开销, 使用有效存储器访问时间 effective memory access time (EAT)\nEAT = 访存时间 * 页表命中几率 + page fault处理时间 * page fault几率\n","categories":["操作系统"],"tags":["内存分配"]},{"title":"第四章 非连续内存分配","url":"/2022/02/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter4%E9%9D%9E%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","content":"第四章 非连续内存分配\n为什么需要非连续内存分配\n\n连续内存分配的缺点\n\n分配给一个程序的物理内存是连续的\n内存利用率低\n有外碎片，内碎片的问题\n\n非连续内存分配的优点\n\n一个程序的物理地址是非连续的\n更好的内存利用和管理\n允许共享代码与数据（共享库等）\n支持动态加载和动态链接\n\n非连续分配缺点\n\n如何建立虚拟地址和物理地址之间的转换\n软件方案\n硬件方案（分段，分页）\n\n\n\n4.1 分段\n程序的分段地址空间，分段寻址方案\n\n计算机程序由各种段组成\n\n分段：更好的分离和共享\n\n\n\n左边连续的虚拟地址，右边不连续的物理地址，采用映射机制进行两边的关联\n\n分段寻址方案\n\n\n一个段：一个内存“块”\n\n\n程序访问内存需要：\n\n\n一个2维的二元组（s，addr）\ns—段号\naddr—段内偏移\n\n\n\n\n操作系统建立段表\n分页\n划分物理内存至固定大小的帧\n\n大小是2的幂，e.g.，512,4096,8192\n\n\n划分逻辑地址空间至相同大小的页\n\n大小同物理地址\n\n\n建立方案 转换逻辑地址为物理地址（pages to frames）\n\n页表\nMMU/TLB（加速地址的转换）\n\n\n\n帧（Frame）\n物理内存被分割为大小相等的帧\n\n一个内存物理地址是一个二元组（f，o）\n\nf—帧号（F位，共有2F个帧）\no—帧内偏移（S位，每帧有2S字节）\n物理地址=2S * f + o\n\n\n16-bit地址空间, 9-bit(512 byte) 大小的页帧\n\n物理地址=（3，6）\n物理地址=1542\n\n\n\n\n页（Page）\n一个程序的逻辑地址空间被划分为大小相等的页\n\n页内偏移的大小 = 帧内偏移的大小\n页号大小 &lt;&gt; 帧号大小\n\n\n一个逻辑地址是一个二元组(p, o) \n\np—页号（P位，2P个页）\no—页内偏移（S位，每页有2S字节）\n逻辑地址=2S * P + o\n\n\n\n页寻址机制\n\n操作系统建立页表\n\n逻辑地址空间应当大于物理内存空间\n页映射到帧\n页是连续的虚拟内存\n帧是非连续的物理内存(有助于减少碎片的产生)\n不是所有的页都有对应的帧\n\n4.3 页表-概述、TLB页表概述页表结构\n\n每一个运行的程序都有一个页表\n属于程序运行状态, 会动态变化\nPTBR : 页表基址寄存器\n\n\n\n地址转换\n\n分页机制的性能问题\n问题：访问一个内存单元需要2次内存访问\n\n一次用于获取页表项\n一次用于访问数据\n\n页表可能非常大\n\n64位机器如果每页1024字节, 那么一个页表的大小会是多少？(264 / 210 = 254 存放不下)\n每一个运行的程序都需要有一个页表\n\n如何处理\n\n缓存\n间接访问\n\nTranslation Look-aside Buffer（TLB）（解决速度上问题）CPU的MMU里面的一个缓冲，CPU中的快表\n缓存近期访问的页帧转换表项\n\nTLB使用associative memory（关联内存）实现, 具备快速访问性能\n如果TLB命中, 物理页号可以很快被获取\n如果TLB未命中, 对应的表项被更新到TLB中\n常用的表项放在TLB里面\nTLB的miss不会很大\n写程序时，写出的程序尽量具有访问的局部性，把平时的访问集中在一个区域里，有效较少TLB的缺失\nx86的CPU由硬件实现, 其他的可能是由操作系统实现\n\n4.4 页表-二级，多级页表二级页表（解决空间上问题）\n\n将页号分为两个部分, 页表分为两个, 一级页号对应一级页表, 二级页号对应二级页表.\n一级页号查表获得在二级页表的起始地址, 地址加上二级页号的值, 在二级页表中获得帧号\n节约了一定的空间, 在一级页表中如果resident bit = 0, 可以使得在二级页表中不存储相关index,而只有一张页表的话, 这一些index都需要保留多级页表\n\n\n通过把页号分为k个部分, 来实现多级间接页表, 建立一棵页表”树”\n\n4.5 页表-反向页表大地址空间问题\n\n有大地址空间(64-bits), 前向映射页表变得繁琐. 比如 : 使用了5级页表\n不是让页表与逻辑地址空间的大小相对应, 而是让页表与物理地址空间的大小相对应. 逻辑地址空间增长速度快于物理地址空间 \n\n基于页寄存器（page registers）的方案每一个帧和一个寄存器关联, 寄存器内容包括 :\n\nresident bit : 此帧是否被占用\noccupier : 对应的页号 p\nprotection bits : 保护位\n\n实例\n\n物理内存大小是 : 4096 * 4096 = 4K * 4KB = 16 MB\n页面大小是 : 4096 bytes = 4 KB\n页帧数 : 4096 = 4 K\n页寄存器使用的空间(假设8 bytes / register) : 8 * 4096 = 32 Kbytes\n页寄存器带来的额外开销 : 32K / 16M = 0.2%\n虚拟内存大小 : 任意\n\n优势\n\n转换表的大小相对于物理内存来说很小\n转换表的大小跟逻辑地址空间的大小无关\n\n劣势\n\n需要的信息对调了, 即根据帧号可以找到页号\n如何转换回来? (如何根据页号找到帧号)\n在需要在反向页表中搜索想要的页号\n\n基于关联内存(associative memory)的方案硬件逻辑复杂，容量不能做太大，还需要放到CPU里面\n\n如果帧数较少, 页寄存器可以被放置在关联内存中\n\n在关联内存中查找逻辑页号\n\n成功 : 帧号被提取\n失败 : 页错误异常 (page fault)\n\n\n限制因素：\n\n大量的关联内存非常昂贵(难以在单个时钟周期内完成 ; 耗电)\n\n\n\n基于哈希(hash)的方案哈希表，哈希函数 : h(PID, p) 从 PID 标号获得页号\n在反向页表中通过哈希算法来搜索一个页对应的帧号\n\n对页号做哈希计算, 为了在帧表中获取对应的帧号\n页 i 被放置在表 f(i) 位置, 其中 f 是设定的哈希函数\n为了查找页 i , 执行下列操作 :\n计算哈希函数 f(i) 并且使用它作为页寄存器表的索引, 获取对应的页寄存器\n检查寄存器标签是否包含 i, 如果包含, 则代表成功, 否则失败\n\n\n\n","categories":["操作系统"],"tags":["内存分配"]},{"title":"绪论","url":"/2021/12/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%BB%AA%E8%AE%BA/","content":"绪论计算计算是：\n\n研究对象：研究计算过程中所蕴含本质的内在规律，总结挖掘出其中的一般性的方法以及典型的技巧\n研究目的：实现高效，低耗的计算\n\n算法：即在特定计算模型下，旨在解决特定问题的指令序列\n程序！=算法\n有穷性：\n对于任何输入，经有穷次基本操作，都可以得到输出 \n好算法=正确+健壮+可读+效率（速度快，空间少）\n图灵机\n进行复位是为了在软件开发过程中相互合作的准则，即规范\nRAM模型\n一个算法好不好并不取决于CPU主频运行的快慢， 而取决于它本身需要执行多少次CPU的计算\n\n\n执行过程可以记录为一张表\n表的行数既是所执行基本指令的总条数\n能够客观度量算法的执行时间\n\n图灵机、RAM等模型为度量算法性能提供了准确的尺度\n渐进复杂度在考察DSA时应该更多看中它的长远（处理更大问题时的潜力如何），也不必过多的纠结于它的细微不足，应该更多的看到它的主要方面，主流\n大O记号从悲观的角度做分析\n\n长远，当n足够大；主流，忽略所有常系数与低次项这些非主流的因素，使得主流信息可以突出\n复杂度分析算法分析的两个主要任务=正确性（不变形x单调性）+复杂度\n复杂度分析的主要方法\n\n迭代：级数求和\n递归：递归跟踪+递归方程\n猜测+验证\n\n级数\n\n循环\n从渐进的阶次而言，二者是完全相等的，都是平方的量级\n起泡排序\n问题：该算法必然会结束？至多需迭代多少趟？\n不变形：经k轮扫描交换后，最大的k个元素必然就位\n单调性：经k轮扫描后交换后，问题规模缩减至n-k\n正确性：经至多n趟扫描后，算法必然会终止，且能给出正确的答案\n\n封底估算除了大O计算这种定性的定界方法，在很多时候需要准确的定量估算\n迭代与递归减而治之\n空间复杂度考量除了输入本身所占的空间之外，所需要的另加用于计算所必须的空间总量\n\n为求解一个大规模的问题，可以将其划分为两个子问题：其一平凡，另一规模缩减\n递归跟踪：直观形象，仅适用于简明的递归模式\n\n递推方程：间接抽象，更适用于复杂的递归模式\n\n\n分而治之为求解一个大规模的问题，可以将其划分为若干子（通常两个）问题，规模大体相当\n\n\n动态规划fib的封底估算\n\nfib递归跟踪\n\nfib迭代\n\n解决方法（记忆）：将已计算过实例的结果制表备查\n解决方法（动态规划）：颠倒计算方法，由自顶而下递归，为自底而上迭代 \n\n公共子序列\n减而治之：将相同的末字符切掉，分成一个平凡的问题和一个小于1的相同规模问题\n\n分而治之：若末尾字符不相同，则大胆切除\n\n单调性：无论如何，每经过一次对比，原问题的规模必可减小。具体地，作为输入的两个序列，至少其一的长度缩短一个单位\n最好情况（不出现第2种情况）下，只需O（n+m）时间\n但问题在于，（在第2种情况）原问题将分解为两个子问题，更糟糕的是，它们在随后进一步导出的子问题，可能雷同\n","categories":["数据结构"],"tags":["数据结构与算法"]}]