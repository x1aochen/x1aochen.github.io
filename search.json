[{"title":"第三章 物理内存分配","url":"/2021/11/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter3%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","content":"第三章 物理内存分配3.1 计算机体系结构及内存分层体系计算机体系结构计算机组成原理\nCPU，内存，总线，I/O\n内存体系结构OS内存管理目标\n抽象（逻辑地址空间）：应用程序不需要考虑底层细节\n保护（独立地址空间）：内存中可以运行多个应用程序，多个程序可能访问别的程序的地址空间或者破坏其他程序\n共享（访问相同内存）：进程之间安全有效可靠的数据传递\n虚拟化（更多的地址空间）：当内存不够时，把最需要的数据放在内存中，暂时不需要访问的数据可以临时的放到硬盘上\n\nOS内存管理方法\n程序重定位\n分段\n分页\n虚拟内存\n按需分页虚拟内存\n\n实现高度依赖于硬件\n\nMMU（内存管理单元）：硬件组件负责处理CPU的内存访问请求\n\n3.2 地址空间与地址生成地址空间物理地址空间——硬件支持的地址空间（起始0，MAX_sys）\n逻辑地址空间——一个运行的程序所拥有的的内存范围（0，MAX_prog）\n逻辑地址的生成\n\n物理地址的生成\n\n\n地址安全检查\n\n3.3 连续内存分配内存碎片内存碎片问题指的是空闲的内存无法被利用\n\n外部碎片：分配单元之间的未使用内存\n内部碎片 :  分配给应用程序的单元内的未使用内存\n\n分区的动态分配\n第一匹配分配：在内存中找到第一个比需求大的空闲块, 分配给应用程序\n\n\n\n\n分配方式\n第一匹配分配\n最优适配分配\n最差适配分配\n\n\n\n实现需求\n1. 按地址排序的空闲块列表2. 分配需要寻找一个合适的分区3. 重分配需要检查是否可以合并相邻空闲分区\n1. 按尺寸排序的空闲块列表2. 分配需要寻找一个合适的分区3. 重分配需要检查是否可以合并相邻空闲分区\n1. 按尺寸排序的空闲块列表2. 分配最大的分区3. 重分配需要检查是否可以合并相邻空闲分区\n\n\n优势\n简单 / 易于产生更大空闲块\n比较简单 / 大部分分配是小尺寸时有效\n分配很快 / 大部分分配是中尺寸时高效\n\n\n劣势\n产生外部碎片 / 不确定性\n产生外部碎片 / 重分配慢 / 易产生很多没用的微小碎片\n产生外部碎片 / 重分配慢 / 易于破碎大的空闲块以致大分区无法被分配\n\n\n3.4 连续内存分配：压缩式与交换式碎片整理无论使用那种算法，都可能产生碎片，希望想有一些办法使得碎片减少甚至消失\n压缩式碎片整理\n重置程序以合并空洞\n要求所有程序是动态可充值的\n议题\n何时重置？\n开销\n\n\n\n\n通过拷贝完成（重定位）\n在运行的时候挪操作，地址会不对\n\n应在程序停止时进行\n\n开销很大，甚至可能影响整个系统的正常执行\n\n\n交换式碎片整理\n运行程序需要更多的内存\n抢占等待的程序&amp;回收他们的内存(把暂时不用的内容挪到磁盘里)\n议题：哪些程序应该被抢占以及什么时候执行\n\n\n操作系统内核特征\n\n并发：计算机系统中同时存在多个运行的程序，需要OS管理和调度\n共享：宏观上“同时访问”，微观上互斥共享\n虚拟：利用多到程序设计技术，让每个用户都觉得有一个计算机专门为他服务\n异步：程序的执行不是一贯到底，而是走走停停，向前推进的速度不可预知，只要运行环境相同，OS需要保证程序运行的结果也要相同\n\n","categories":["操作系统"],"tags":["内存分配"]},{"title":"第四章 非连续内存分配","url":"/2021/11/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter4%E9%9D%9E%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","content":"第四章 非连续内存分配\n为什么需要非连续内存分配\n\n连续内存分配的缺点\n\n分配给一个程序的物理内存是连续的\n内存利用率低\n有外碎片，内碎片的问题\n\n非连续内存分配的优点\n\n一个程序的物理地址是非连续的\n更好的内存利用和管理\n允许共享代码与数据（共享库等）\n支持动态加载和动态链接\n\n非连续分配缺点\n\n如何建立虚拟地址和物理地址之间的转换\n软件方案\n硬件方案（分段，分页）\n\n\n\n4.1 分段\n程序的分段地址空间，分段寻址方案\n\n计算机程序由各种段组成\n\n分段：更好的分离和共享\n\n\n\n左边连续的虚拟地址，右边不连续的物理地址，采用映射机制进行两边的关联\n\n分段寻址方案\n\n\n一个段：一个内存“块”\n\n\n程序访问内存需要：\n\n\n一个2维的二元组（s，addr）\ns—段号\naddr—段内偏移\n\n\n\n\n操作系统建立段表\n分页\n划分物理内存至固定大小的帧\n\n大小是2的幂，e.g.，512,4096,8192\n\n\n划分逻辑地址空间至相同大小的页\n\n大小同物理地址\n\n\n建立方案 转换逻辑地址为物理地址（pages to frames）\n\n页表\nMMU/TLB（加速地址的转换）\n\n\n\n帧（Frame）\n物理内存被分割为大小相等的帧\n\n一个内存物理地址是一个二元组（f，o）\n\nf—帧号（F位，共有2F个帧）\no—帧内偏移（S位，每帧有2S字节）\n物理地址=2S * f + o\n\n\n16-bit地址空间, 9-bit(512 byte) 大小的页帧\n\n物理地址=（3，6）\n物理地址=1542\n\n\n\n\n页（Page）\n一个程序的逻辑地址空间被划分为大小相等的页\n\n页内偏移的大小 = 帧内偏移的大小\n页号大小 &lt;&gt; 帧号大小\n\n\n一个逻辑地址是一个二元组(p, o) \n\np—页号（P位，2P个页）\no—页内偏移（S位，每页有2S字节）\n逻辑地址=2S * P + o\n\n\n\n页寻址机制\n\n操作系统建立页表\n\n逻辑地址空间应当大于物理内存空间\n页映射到帧\n页是连续的虚拟内存\n帧是非连续的物理内存(有助于减少碎片的产生)\n不是所有的页都有对应的帧\n\n4.3 页表-概述、TLB页表概述页表结构\n\n每一个运行的程序都有一个页表\n属于程序运行状态, 会动态变化\nPTBR : 页表基址寄存器\n\n\n\n地址转换\n\n分页机制的性能问题\n问题：访问一个内存单元需要2次内存访问\n\n一次用于获取页表项\n一次用于访问数据\n\n页表可能非常大\n\n64位机器如果每页1024字节, 那么一个页表的大小会是多少？(264 / 210 = 254 存放不下)\n每一个运行的程序都需要有一个页表\n\n如何处理\n\n缓存\n间接访问\n\nTranslation Look-aside Buffer（TLB）（解决速度上问题）CPU的MMU里面的一个缓冲，CPU中的快表\n缓存近期访问的页帧转换表项\n\nTLB使用associative memory（关联内存）实现, 具备快速访问性能\n如果TLB命中, 物理页号可以很快被获取\n如果TLB未命中, 对应的表项被更新到TLB中\n常用的表项放在TLB里面\nTLB的miss不会很大\n写程序时，写出的程序尽量具有访问的局部性，把平时的访问集中在一个区域里，有效较少TLB的缺失\nx86的CPU由硬件实现, 其他的可能是由操作系统实现\n\n4.4 页表-二级，多级页表二级页表（解决空间上问题）\n\n将页号分为两个部分, 页表分为两个, 一级页号对应一级页表, 二级页号对应二级页表.\n一级页号查表获得在二级页表的起始地址, 地址加上二级页号的值, 在二级页表中获得帧号\n节约了一定的空间, 在一级页表中如果resident bit = 0, 可以使得在二级页表中不存储相关index,而只有一张页表的话, 这一些index都需要保留多级页表\n\n\n通过把页号分为k个部分, 来实现多级间接页表, 建立一棵页表”树”\n\n4.5 页表-反向页表大地址空间问题\n\n有大地址空间(64-bits), 前向映射页表变得繁琐. 比如 : 使用了5级页表\n不是让页表与逻辑地址空间的大小相对应, 而是让页表与物理地址空间的大小相对应. 逻辑地址空间增长速度快于物理地址空间 \n\n基于页寄存器（page registers）的方案每一个帧和一个寄存器关联, 寄存器内容包括 :\n\nresident bit : 此帧是否被占用\noccupier : 对应的页号 p\nprotection bits : 保护位\n\n实例\n\n物理内存大小是 : 4096 * 4096 = 4K * 4KB = 16 MB\n页面大小是 : 4096 bytes = 4 KB\n页帧数 : 4096 = 4 K\n页寄存器使用的空间(假设8 bytes / register) : 8 * 4096 = 32 Kbytes\n页寄存器带来的额外开销 : 32K / 16M = 0.2%\n虚拟内存大小 : 任意\n\n优势\n\n转换表的大小相对于物理内存来说很小\n转换表的大小跟逻辑地址空间的大小无关\n\n劣势\n\n需要的信息对调了, 即根据帧号可以找到页号\n如何转换回来? (如何根据页号找到帧号)\n在需要在反向页表中搜索想要的页号\n\n基于关联内存(associative memory)的方案硬件逻辑复杂，容量不能做太大，还需要放到CPU里面\n\n如果帧数较少, 页寄存器可以被放置在关联内存中\n\n在关联内存中查找逻辑页号\n\n成功 : 帧号被提取\n失败 : 页错误异常 (page fault)\n\n\n限制因素：\n\n大量的关联内存非常昂贵(难以在单个时钟周期内完成 ; 耗电)\n\n\n\n基于哈希(hash)的方案哈希表，哈希函数 : h(PID, p) 从 PID 标号获得页号\n在反向页表中通过哈希算法来搜索一个页对应的帧号\n\n对页号做哈希计算, 为了在帧表中获取对应的帧号\n页 i 被放置在表 f(i) 位置, 其中 f 是设定的哈希函数\n为了查找页 i , 执行下列操作 :\n计算哈希函数 f(i) 并且使用它作为页寄存器表的索引, 获取对应的页寄存器\n检查寄存器标签是否包含 i, 如果包含, 则代表成功, 否则失败\n\n\n\n","categories":["操作系统"],"tags":["内存分配"]},{"title":"第六章 页面置换算法","url":"/2021/11/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter6%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/","content":"第六章 页面置换算法6.1 页面置换算法功能与目标功能：当缺页中断发生，需要调入新的页面而内存已满时，选择内存当中哪个页面被置换\n目标：尽可能地减少页面的换进换出次数（即缺页中断的次数）。具体的说，把未来不再使用或短期内较少使用的页面换出，通常只能在局部性原理知道下依据过去的统计数据来进行预测\n页面锁定（frame locking）：用于描述必须常驻内存的操作系统的关键部分或时间关键（time-critical）的应用进程。实现方法是：在页表中添加锁定标志（lock bit）\n实验设置\n记录一个进程对页访问的一个轨迹\n\n举例：（虚拟）地址跟踪（页号，位移）…\n\n（3,0），（1,9），（4,1），（2,1），（5,3），（2,0），（1,9），…\n\n\n生成页面轨迹\n\n3, 1, 4, 2, 5, 2, 1,…..\n\n\n\n模拟一个页面置换的行为并且记录产生页缺失数的数量\n\n更少的缺失，更好的性能\n\n最优页面置换算法\n基本思路：当一个缺页中断发生时, 对于保存在内存当中的每一个逻辑页面, 计算在它的下一次访问之前, 还需等待多长时间, 从中选择等待时间最长的那个, 作为被置换的页面\n这只是一种理想情况, 在实际系统中是无法实现的, 因为操作系统无法知道每一个页面要等待多长时间以后才会再次被访问\n可用作其他算法的性能评价的依据.(在一个模拟器上运行某个程序, 并记录每一次的页面访问情况, 在第二遍运行时即可使用最优算法)\n\n\n局部页面置换算法6.2 先进先出算法First-In First-out，FIFO\n\n基本思路： 选择在内存中驻留时间最长的页面淘汰. 具体来说, 系统维护着一个链表, 记录了所有位于内存当中的逻辑页面. 从链表的排列顺序来看, 链首页面的驻留时间最长, 链尾页面的驻留时间最短. 当发生一个缺页中断时, 把链首页面淘汰出去, 并把新的页面添加到链表的末尾\n\n性能较差, 调出的页面有可能是经常要访问的页面. 并且有 Belady现象. FIFO算法很少单独使用\n\n\n6.3 最近最久未使用算法Least Recently Used，LRU\n\n基本思路 : 当一个缺页中断发生时, 选择最久未使用的那个页面, 并淘汰\n它是对最优页面置换算法的一个近似, 其依据是程序的局部性原理, 即在最近一小段时间(最近几条指令)内, 如果某些页面被频繁地访问, 那么再将来的一小段时间内, 他们还可能会再一次被频繁地访问. 反过来说, 如果过去某些页面长时间未被访问, 那么在将来它们还可能会长时间地得不到访问（根据过去来实现）\nLRU算法需要记录各个页面使用时间的先后顺序, 开销比较大\n两种可能得实现方法：\n系统维护一个页面链表, 最近刚刚使用过的页面作为首节点, 最久未使用的作为尾结点. 再一次访问内存时, 找出相应的页面, 把它从链表中摘下来, 再移动到链表首. 每次缺页中断发生时, 淘汰链表末尾的页面\n设置一个活动页面栈, 当访问某页时, 将此页号压入栈顶, 然后, 考察栈内是否有与此页面相同的页号, 若有则抽出. 当需要淘汰一个页面时, 总是选择栈底的页面, 它就是最久未使用的\n\n\n\n6.4 时钟页面置换算法Clock页面置换算法，LRU的近视，对FIFO的一种改进\n\n基本思路\n需要用到页表项的访问位, 当一个页面被装入内存时, 把该位初始化为0. 然后如果这个页面被访问, 则把该位置设为1\n把各个页面组织成环形链表(类似钟表面), 把指针指向最老的页面(最先进来)\n当发生一个缺页中断时, 考察指针所指向的最老页面, 若它的访问位为0, 立即淘汰; 若访问位为0, 然后指针往下移动一格. 如此下去, 直到找到被淘汰的页面, 然后把指针移动到下一格\n\n\n\n\n6.5 二次机会法“脏”位区分读（0）和写（1）\n访问位与“脏”位的结合，减少写回操作的次数\n\n替换used和dirty都是0的页\n把经常使用的页留在内存中\n\n相当于说, 替换的优先级, 没有读写也没写过, 那么直接走, 如果写过或者访问过, 那么给你一次机会, 如果又写过, 又访问过, 那么久给你两次机会\n\n6.6 最不常用算法Least Frequently Used ,LFU\n\n基本思路 : 当一个缺页中断发生时, 选择访问次数最少的那个页面, 并淘汰\n实现方法 : 对每一个页面设置一个访问计数器, 每当一个页面被访问时, 该页面的访问计数器加1. 当发生缺页中断时, 淘汰计数值最小的那个页面\nLRU和LFU的对比 : LRU考察的是多久未访问, 时间越短越好. 而LFU考察的是访问的次数和频度, 访问次数越多越好\n\n6.7 Belady现象、LRU、FIFO、Clock的比较Belady现象在采用FIFO算法时, 有时会出现分配的物理页面数增加, 缺页率反而提高的异常现象\n现象原因：FIFO算法的置换特征与进程访问内存的动态特征是矛盾的, 与置换算法的目标是不一致的(即替换较少使用的页面), 因此, 被他置换出去的页面不一定是进程不会访问的\n\n给更多的物理页却产生更多的缺页\nLRU、FIFO和Clock的比较\nLRU和FIFO都是先进先出的思路, 只不过LRU是针对页面最近访问时间来进行排序, 所以需要在每一次页面访问的时候动态地调整各个页面之间的先后顺序(有一个页面的最近访问时间变了). 而FIFO是针对页面进入内存的时间来进行排序, 这个时间是固定不变的, 所以各个页面之间的先后顺序是固定的. 如果一个页面在进入内存后没有被访问, 那么它的最近访问时间就是它进入内存的时间. 换句话说, 如果内存当中的所有页面都未曾访问过, 那么LRU算法就退化为了FIFO算法\nLRU算法性能较好，但系统开销较大; FIFO算法系统开销较小，但可能会发生Belady现象。因此，折衷的办法就是Clock算法，在每一次页面访问时，它不必去动态地调整该页面在链表当中的顺序，而仅仅是做一个标记，然后等到发生缺页中断的时候，再把它移动到链表末尾。对于内存当中那些末被访问的页面，Clock算法的表现和LRU算法一样好: 而对于那些曾经被访问过的页面，它不能象LRU算法那样，记住它们的准确位置。\n\n全局页面置换算法6.8 局部页替换算法的问题、工作机模型全局页面置换算法考虑的问题：根据程序不同的运行阶段，动态分配调整物理页帧的算法\n工作集模型前面介绍的各种页面置换算法, 都是基于一个前提, 即程序的局部性原理. 但是此原理是否成立？\n\n如果局部性原理不成立, 那么各种页面置换算法就没有说明分别, 也没有什么意义. 例如 : 假设进程对逻辑页面的访问顺序是1,2,3,4,5,6,6,7,8,9…, 即单调递增, 那么在物理页面数有限的前提下, 不管采用何种置换算法, 每次的页面访问都必然导致缺页中断\n如果局部性原理是成立的，那么如何来证明它的存在，如何来对它进行定量地分析? 这就是工作集模型\n\n工作集：一个进程当前正在使用的逻辑页面集合\n可以使用一个二元函数 W(t, △delta) 来表示\n\nt 是当前的执行时刻\ndelta 称为工作集窗口, 即一个定长的页面访问的时间窗口\nW(t, delta) = 在当前时刻 t 之前的 delta 时间窗口当中的所有页面所组成的集合(随着 t 的变化, 该集合也在不断的变化)\n|W(t, delta)| 是工作集的大小, 即逻辑页的数量\n\n\nt2具有很好的局部性\nt1具有一定的局部性（重复访问7）\n\n常驻集常驻集是指在当前时刻, 进程实际驻留在内存当中的页面集合\n\n工作集是进程在运行过程中固有的性质, 而常驻集取决于系统分配给进程的物理页面数目, 以及所采用的页面置换算法\n如果一个进程的整个工作集都在内存当中, 即常驻集包含工作集, 那么进程将很顺利地运行, 而不会造成太多的缺页中断(直到工作集发生剧烈变动, 从而过渡到另一个状态)\n当进程常驻集的大小达到某个数目之后, 再给它分配更多的物理页面, 缺页率也不会明显下降\n\n6.9 两个全局置换算法工作集页置换算法\n当工作集窗口在滑动过程中, 如果页面不在集合中, 那么就会直接丢失这个不在窗口中页面, 而不会等待缺页中断再丢弃\n缺页率置换算法可变分配策略： 常驻集大小可变. 例如 : 每个进程在刚开始运行的时候, 先根据程序大小给它分配一定数目的物理页面, 然后在进程运行过程中, 再动态地调整常驻集的大小\n\n可采用全局页面置换的方式, 当发生一个缺页中断时, 被置换的页面可以是在其他进程当中, 各个并发进程竞争地使用物理页面\n优缺点 : 性能较好, 但增加了系统开销\n具体实现 : 可以使用缺页率算法来动态调整常驻集的大小\n\n缺页率 : 表示 “缺页次数 / 内存访问次数”（比率）或“缺页的平均时间间隔的倒数”\n影响因素：\n\n页面置换算法\n分配给进程的物理页面数目\n页面本身的大小\n程序的编写方法\n\n若运行的程序缺页率过高，则通过增加工作集来分配更多的物理页面；若运行的程序缺页率过低，则通过减少工作集来减少它的物理页面数。力图使运行的程序的缺页率保持在一个合理的范围内（寻求balance）\n6.10 抖动问题\n如果分配给一个进程的物理页面太少, 不能包含整个的工作集, 即常驻集 属于 工作集, 那么进程将会造成很多的缺页中断, 需要频繁的在内存与外存之间替换页面, 从而使进程的运行速度变得很慢, 我们把这种状态称为 “抖动”\n产生抖动的原因 : 随着驻留内存的进程数目增加, 分配给每个进程的物理页面数不断就减小, 缺页率不断上升. 所以OS要选择一个适当的进程数目和进程需要的帧数, 以便在并发水平和缺页率之间达到一个平衡\n\n","categories":["操作系统"],"tags":["内存分配"]},{"title":"第五章 虚拟内存","url":"/2021/11/13/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter5%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/","content":"第五章 虚拟内存5.1 起因程序规模的增长远大于存储器容量发展的速度，让更多的程序跑在有限的内存里面\n使用硬盘/磁盘使更多的程序在有限的内存中运行\n理想的存储器：\n更大，更快，更便宜的非易失性存储器\n实际中的存储器：\n\n5.2 覆盖技术目标：是在较小的可用内存中运行较大的程序, 常用于多道程序系统, 与分区存储管理配合使用\n原理：\n\n把程序按照其自身逻辑结构, 划分为若干个功能上相互独立的程序模块, 那些不会同时执行的模块共享同一块内存区域, 按时间先后来运行\n必要部分(常用功能)的代码和数据常驻内存\n可选部分(不常用功能)在其他程序模块中实现, 平时存放在外存中, 在需要用到时才装入内存\n不存在调用关系的模块不必同时装入到内存, 从而可以相互覆盖, 即这些模块共用一个分区\n\n\n\n\n\n缺点：\n由程序员来把一个大的程序划分为若干个小的功能模块, 并确定各个模块之间的覆盖关系, 费时费力, 增加了编程的复杂度\n覆盖模块并从外存装入内存, 实际上是以时间延长来换取空间节省\n\n\n\n5.3 交换技术如果是程序太多, 超过了内存的容量, 可以采用自动的交换(swapping)技术, 把暂时不能执行的程序送到外存中\n目标：\n\n多道程序在内存时, 让正在运行的程序或需要运行的程序获得更多的内存资源\n\n方法：\n\n可将暂时不能运行的程序送到外存, 从而获得空闲内存空间\n操作系统把一个进程的整个地址空间的内容保存到外存中(换出 swap out), 而将外存中的某个进程的地址空间读入到内存中(换入 swap in). 换入换出内容的大小为整个程序的地址空间\n\n交换技术实现中的几个问题：\n\n交换时机的确定 : 何时需要发生交换? 只当内存空间不够或有不够的危险时换出\n交换区的大小 : 必须足够大以存放所有用户进程的所有内存映像的拷贝, 必须能够对这些内存映像进行直接存取\n程序换入时的重定位 : 换出后再换入的内存位置一定要在原来的位置上嘛?(可能出现寻址问题) 最好采用动态地址映射的方法\n\n覆盖与交换的比较\n\n覆盖只能发生在那些相互之间没有调用关系的程序模块之间, 因此程序员必须给出程序内的各个模块之间的逻辑覆盖结构\n交换技术是以在内存中的程序大小为单位进行的, 它不需要程序员给出各个模块之间的逻辑覆盖结构。换言之, 交换发生在内存中程序与管理程序或操作系统之间, 而覆盖则发生在运行程序的内部\n\n5.4 虚存技术在内存不够用的情形下, 可以采用覆盖技术和交换技术, 但是 :\n\n覆盖技术 : 需要程序要自己把整个程序划分为若干个小的功能模块, 并确定各个模块之间的覆盖关系, 增加了程序员的负担\n交换技术 : 以进程作为交换的单位, 需要把进程的整个地址空间都换入换出, 增加了处理器的开销\n\n目标：\n\n像覆盖技术那样, 不是把程序的所有内容都放在内存中, 因而能够运行比当前的空闲内存空间还要大的程序. 但做的更好, 由操作系统自动来完成, 无需程序员的干涉\n像交换技术那样, 能够实现进程在内存与外存之间的交换, 因而获得更多的空闲内存空间. 但做的更好, 只对进程的部分内容在内存和外存之间进行交换\n以更小的页粒度为单位装入更多更大的程序\n\n程序的局部性原理\n\n程序的局部性原理(principle of locality) : 指程序在执行过程中的一个较短时期, 所执行的指令地址和指令的操作数地址, 分别局限于一定的区域\n时间局部性 : 一条指令的一次执行和下次执行, 一个数据的一次访问和下次访问都集中在一个较短时期内\n空间局部性 : 当前指令和邻近的几条指令, 当前访问的数据和邻近的几个数据都集中在一个较小区域内\n\n\n\n程序的局部性原理表明, 从理论上来说, 虚拟存储技术是能够实现的. 而且在实现了以后应该是能够取得一个满意的效果\n实例：\n页面大小为4k, 分配给每个进程的物理页面是1. 在一个进程中, 定义了如下的二维数组 int A[1024][1024]. 该数组按行存放在内存, 每一行放在一个页面中.考虑一下程序的编写方法对缺页率的影响?程序编写方法1 : (发生了1024*1024次缺页中断)for(j = 0; j &lt; 1024; j++)\t\tfor(i = 0; i &lt; 1024; i++)\t\t\t\tA[i][j] = 0;程序编写方法2 : (发生了1024次缺页中断)for(i = 0; i &lt; 1024; i++)\t\tfor(j = 0; j &lt; 1024; j++)\t\t\t\tA[i][j] = 0;\n\n基本概念\n可以在页式或段式内存管理的基础上实现\n\n在装入程序时, 不必将其全部装入内存, 而只需将当前需要执行的部分页面或段装入到内存中, 就可以让程序开始执行\n在程序执行过程中, 如果需执行的指令或访问的数据尚未在内存中(称为缺页或缺段), 则由处理器通知操作系统将相应的页面或段调入到内存, 然后继续执行程序\n另一方面, 操作系统将内存中暂时不使用的页面或段调出保存在外存上, 从而腾出更多空闲内存空间存放将要装入的程序以及将要调入的页面或段\n\n基本特征\n\n大的用户空间 : 通过把物理内存和外存相结合, 提供给用户的虚拟内存空间通常大于实际的物理内存, 即实现了这两者的分离. 如32位的虚拟地址理论上可以访问4GB, 而可能计算机上仅有256M的物理内存, 但硬盘容量大于4GB\n部分交换 : 与交换技术相比较, 虚拟存储的调入和调出是对部分虚拟地址空间进行的\n不连续性 : 物理内存分配的不连续性, 虚拟地址空间使用的不连续性\n\n页式内存管理页表 : 完成逻辑页到物理页帧的映射\n根据页号去页表中寻找索引, 先查看 resident bit 是否为0, 0表示不存在, 1表示映射关系存在, 获得帧号加上原本的偏移, 获得了物理地址\n虚拟页式内存管理\n\n大部分虚拟存储系统都采用虚拟页式存储管理技术, 即在页式存储管理的基础上, 增加请求调页和页面置换功能\n\n基本思路\n\n当一个用户程序要调入内存运行时, 不是将该程序的所有页面都装入内存, 而是只装入部分的页面, 就可启动程序运行.\n在运行的过程中, 如果发现要运行的程序或要访问的数据不再内存, 则向系统发出缺页的中断请求, 系统在处理这个中断时, 将外存中相应的页面调入内存, 使得该程序能够继续运行\n\n\n页表表项\n\n驻留位 : 表示该页是在内存中还是在外存\n保护位 : 表示允许对该页做何种类型的访问, 如只读, 可读写, 可执行等\n修改位 : 表示此页在内存中是否被修改过. 当系统回收该物理页面时, 根据此位来决定是否把它的内容写回外存\n访问位 : 如果该页被访问过(包括读写操作), 则设置此位. 用于页面置换算法\n\n\n缺页中断处理过程\n\n如果在内存中有空闲的物理页面, 则分配一物理页帧f, 然后转第4步; 否则转到第2步\n采用某种页面置换算法, 选择一个将被替换的物理页帧f, 它所对应的逻辑页为q, 如果该页在内存期间被修改过, 则需要把它写回外存\n对q所对应的页表项修改, 把驻留位置为0\n将需要访问的页p装入到物理页面f当中\n修改p所对应的页表项的内容, 把驻留位置为1, 把物理页帧号置为f\n重新运行被中断是指令\n\n\n\n在何处保存未被映射的页？\n\n能够简单地识别在二级存储器中的页\n交换空间(磁盘或者文件) : 特殊格式, 用于存储未被映射的页面\n\n后备存储 backing store（二级存储）\n一个虚拟地址空间的页面可以被映射到一个文件(在二级存储中)的某个位置\n代码段 : 映射到可执行二进制文件\n动态加载的共享库程序段 : 映射到动态调用的库文件\n其他段 : 可能被映射到交换文件(swap file)\n\n虚拟内存性能为了便于理解分页的开销, 使用有效存储器访问时间 effective memory access time (EAT)\nEAT = 访存时间 * 页表命中几率 + page fault处理时间 * page fault几率\n","categories":["操作系统"],"tags":["内存分配"]},{"title":"第八章 调度算法","url":"/2021/11/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter8%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/","content":"第八章 调度算法8.1 背景上下文切换\n\n切换CPU的当前任务, 从一个进程/线程到另一个\n保存当前进程/线程在PCB/TCB中的执行上下文(CPU状态)\n读取下一个进程/线程的上下文\n\nCPU调度\n\n从就绪队列中挑选一个进程/线程作为CPU将要运行的下一个进程/线程\n调度程序：挑选进程/线程的内核函数(通过一些调度策略)\n什么时候进行调度？\n\n内核运行调度程序的条件（满足一条即可）\n\n一个进程从运行状态切换到等待状态\n一个进程被终结了\n\n不可抢占\n\n调度程序必须等待事件结束\n\n可以抢占\n\n调度程序在中断被响应后执行\n当前的进程从运行切换到就绪，或者一个进程从等待切换到就绪\n当前运行的进程可以被换出\n\n8.2 调度原则评价指标\n\nCPU使用率：CPU处于忙状态所占时间的百分比\n吞吐量：在单位时间内完成的进程数量\n周转时间：一个进程从初始化到结束，包括所有等待时间所花费的时间\n等待时间：进程在就绪队列中的总时间\n响应时间：从一个请求被提交到产生第一次相应所花费的总时间\n\n人们通常都需要“更快”的服务\n什么是更快\n\n传输文件时的高带宽\n玩游戏时的低延迟\n这两个因素是独立的\n\n和水管类比\n\n低延迟：喝水的时候想要一打开水龙头水就流出来\n高带宽：给游泳池冲水时希望从水龙头里同时流出大量的水，并且不介意是否存在延迟\n\n目标：\n\n减少响应时间：及时处理用户的输出并且尽快将输出提供给用户\n\n减少平均响应时间的波动：在交互系统中，可预测性比高差异低平均更重要\n\n增加吞吐量\n\n减少开销（操作系统开销，上下文切换）\n系统资源的高效利用（CPU，I/O设备）\n\n\n减少等待时间：减少每个进程的等待时间\n\n\n各指标在操作系统上的表现：\n\n低延迟调度增加了交互式表现\n\n如果移动了鼠标，但是屏幕中的光标却没动，我们可能会重启电脑\n\n\n操作系统需要保证低吞吐量不受影响\n\n我想要结束长时间的编程，所以操作系统必须不时进行调度，即使存在许多交互任务\n\n\n吞吐量是操作系统的计算带宽\n\n响应时间是操作系统的计算延迟\n\n\n公平的定义\n举例：\n\n保证每个进程占用相同的CPU时间\n这公平嘛?如果一个用户比其他用户运行更多的进程怎么办\n\n举例：\n\n保证每个进程都等待相同的时间\n\n公平通常会增加平均响应时间\n8.3-8.4 调度算法面向通用型计算机系统的调度算法\n\n一. FCFS（先来先去服务）FIFO队列的规定\n\n如果进程在执行中阻塞，队列中的下一个会得到CPU\n\n\n\n优点：简单\n缺点\n平均等待时间波动较大\n花费时间少的任务可能排在花费时间长的任务后面\n可能导致I/O和CPU之间的重叠处理\n\n\n\n二. SPN/SRT 短进程优先Shortest Process Next(Shortest Job First) Shortest Remaining Time\n\n按照预测的完成时间来将任务入队\n\n可以是可抢占或者不可抢占的\n\n可抢占：又叫Shortest-Remaining-Time(SRT)（最短剩余时间）\n\n\n可能导致饥饿\n\n连续的短任务流会使长任务饥饿\n短任务可用时的任何长任务的CPU时间都会增加平均等待时间\n\n\n需要预知未来\n\n怎么预估下一个CPU突发的持续时间\n简单的解决办法：询问用户\n如果用户欺骗就杀死进程\n如果用户不知道怎么办\n从执行历史来推断\n\n\n\n\n\n三. HRRN 最高响应比优先Highest Response Ratio Next（HRRN)\n\n在SPN调度的基础上改进\n不可抢占\n关注进程等待了多长时间\n防止无限期推迟\n\n综合考虑了进程的执行时间和等待时间\n饥饿现象得到有效的缓解\n问题\n\n不可抢占\n依然需要知道进程的执行时间\n\n四. Round Robin 轮循\n\nPR花销：额外的上下文切换\n\n时间量子太大\n\n等待时间过长\n极限情况退化成FCFS\n\n\n时间量子太小\n\n反应迅速\n吞吐量由于大量的上下文切换开销收到影响\n\n\n\n目标：\n\n选择一个合适的时间量子\n经验规则：维持上下文切换开销处于1%以内\n\n五. MLFQ 多级反馈队列Multilevel Feedback Queues\n\n就绪队列被划分成独立的队列：\n比如前台（交互），后台（批处理）\n\n每个队列拥有自己的调度策略：\n比如前台（PR），后台（FCFS）\n\n调度必须在队列间进行\n\n固定优先级\n先处理前台，然后处理后台\n可能导致饥饿\n\n\n时间切片\n每个队列都得到一个确定的能够调度其进程的CPU总时间\n比如，80%给使用PR的前台，20%给使用FCFS的后台\n\n\n\n\n一个进程可以在不同的队列中移动\n\n例如：n级优先级—优先级调度在所有级别中，PR在每个级别中\n\n时间量子大小随优先级别增加而增加\n如果任务在当前的时间量子中没有完成，则降到下一个优先级\n\n\n\n优点\n\nCPU密集型任务的优先级下降很快\nI/O密集型任务停留在高优先级\n\n六. Fair-Share Scheduling 公平共享调度FSS控制用户对系统资源的访问\n\n一些用户组比其他用户组更重要\n保证不重要的组无法垄断资源\n未使用的资源按照每个组所分配的资源的比例来分配\n没有达到资源使用率目标的组获得更高的优先级\n\n8.5 实时调度定义：正确性依赖于时间和功能两方面的一种操作系统\n性能指标：时间约束的及时性；速度和平均性能相对不重要\n主要特性：时间约束的可预测性\n两类：\n\n强实时系统：需要在保证的时间内完成重要任务，必须完成\n弱实时系统：要求重要的进程的优先级更高，尽量完成，并非必须\n\n任务（工作单元）：一次计算，一次文件读取，一次信息传递等等\n属性：取得进展所需要的资源；定时参数\nRM（Rate Monotonic）速率单调调度\n\n最佳静态优先级调度\n通过周期安排优先级\n周期越短优先级越高\n执行周期最短的任务\n\nEDF（Earliest Deadline First）最早期限调度\n\n最佳的动态优先级调度\nDeadline越早优先级越高\n执行Deadline最早的任务\n\n8.6 多处理器调度与优先级反转多处理器的CPU调度更复杂\n\n多个相同的单处理器组成一个多处理器\n优点：复杂共享\n\n对称多处理器（SMP）\n\n每个处理器运行自己的调度程序\n需要在调度程序中同步\n\n优先级反转\n\n可以发生在任务基于优先级的可抢占的调度机制中\n当系统内的环境强制使高优先级任务等待低优先级任务时发生\n\n","categories":["操作系统"],"tags":["调度"]},{"title":"第七章 进程管理","url":"/2021/11/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter7%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","content":"第七章 进程管理7.1-7.4 进程描述进程的定义进程：一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程\n进程的组成一个进程应该包括：\n\n程序的代码\n\n程序处理的数据\n\n程序计数器中的值, 指示下一条将运行的指令\n\n一组通用的寄存器的当前值, 堆, 栈\n\n一组系统资源(如打开的文件)\n\n进程包含了正在运行的一个程序的所有状态信息*\n\n\n进程与程序的联系\n\n程序是产生进程的基础\n程序的每次运行构成不同的进程\n进程是程序功能的体现\n通过多次执行, 一个程序可以对应多个进程, 通过调用关系, 一个进程可包括多个程序\n\n进程与程序的区别：\n\n进程是动态的, 程序是静态的 : 程序是有序代码的集合. 进程是程序的执行, 进程有核心态 / 用户态（进程在执行过程中需要完成特定的只能操作系统提供的功能，进程只需给OS发出请求，OS代表进程在内核中执行，此时进程处于核心态）\n进程是暂时的, 程序是永久的. 进程是一个状态变化的过程, 程序可以长久保存\n进程和程序的组成不同 : 进程的组成包括程序, 数据和进程控制块（进程状态信息）\n\n\n进程的特点\n可动态地创建, 结果进程\n并发性 : 进程可以被独立调度并占用处理机运行; (并发:一段, 并行:一时刻)\n独立性 : 不同进程的工作不相互影响;(页表是保障措施之一)\n制约性 : 因访问共享数据, 资源或进程间同步而产生制约\n\n进程控制结构程序=算法+数据结构\n描述进程的数据结构：进程控制块（Process Control Block，PCB）\n\n进程控制块：操作系统管理控制进程运行所用的信息集合\n操作系统用PCB来描述进程的基本情况以及运行变化的过程，PCB是进程存在唯一标志\n\n使用进程控制块\n\n进程的创建：为该进程生成一个PCB\n进程的终止 : 回收它的PCB\n进程的组织管理：通过对PCB的组织管理来实现\n\nPCB含有以下三大类信息：\n\n进程标志信息。如本进程的标志，本进程的产生者标志（父进程标志），用户标志\n\n处理机状态信息保存区。保存进程的运行现场信息：\n\n用户可见寄存器，用户程序可以使用的数据，地址等寄存器\n控制和状态寄存器，如程序计数器(PC)，程序状态字(PSW)\n栈指针，过程调用/系统调用/中断处理和返回时需要用到它\n\n\n进程控制信息：\n\n调度和状态信息，用于操作系统调度进程并占用处理机使用\n进程间通信信息，为支持进程间与通信相关的各种标志, 信号, 信件等, 这些信息都存在接收方的进程控制块中\n存储管理信息， 包含有指向本进程映像存储空间的数据结构\n进程所用资源 说明由进程打开，使用的系统资源，如打开的文件等\n有关数据结构的链接信息，进程可以连接到一个进程队列中，或连接到相关的其他进程的PCB\n\n\n\nPCB的组织方式\n链表：同一状态的进程其PCB成一链表，多个状态对应多个不同的链表（各状态的进程形成不同的链表：就绪链表，阻塞链表）\n索引表：同一状态的进程归入一个index表（由index指向PCB）， 多个状态对应多个不同的index表（各状态的进行形成不同的索引表 : 就绪索引表, 阻塞索引表）\n7.5-7.7 进程状态进程生命周期管理进程创建\n引进进程创建的3个主要事件：\n\n系统初始化；\n用户请求创建一个新进程；\n正在运行的程序执行了创建进程的系统调用；\n\n进程运行\n内核选择一个就绪的进程，让他占用处理机并执行\n\n为何选择？如何选择？\n\n进程等待\n在以下情况下，进程等待（阻塞）：\n\n请求并等待系统服务, 无法马上完成\n启动某种操作, 无法马上完成\n需要的数据没有到达\n\n进程只能自己阻塞自己, 因为只有进程自身才能知道何时需要等待某种事件的发生\n进程唤醒\n唤醒进程的原因：\n\n被阻塞进程需要的资源可被满足\n被阻塞进程等待的事件到达\n将该进程的PCB插入到就绪队列\n\n进程只能被别的进程或操作系统唤醒\n进程结束\n在以下四种情况下，进程结束：\n\n正常退出(自愿)\n错误退出(自愿)\n致命错误(OS强制性)\n被其他进程杀死(强制性)\n\n进程状态变化模型进程的三种基本状态：进程在生命结束前处于三种基本状态之一\n不同系统设置的进程状态数目不同\n\n运行状态（Running）：当一个进程正在处理机上运行时\n就绪状态（Ready）：一个进程获得了除处理机之外的一切所需资源, 一旦得到处理机即可运行\n等待状态（阻塞状态 Blocked）：一个进程正在等待某一时间而暂停运行时. 如等待某资源, 等待输入/输出完成\n\n进程其他的基本状态：\n创建状态（New）：一个进程正在被创建, 还没被转到就绪状态之前的状态\n结束状态（Exit）：一个进程正在从系统中消失时的状态, 这是因为进程结束或由于其它原因所导致\n\n可能的状态变化如下：\nNULL → New：一个新进程被产生出来执行一个程序\nNew → Ready：当进程创建完成并初始化后, 一切就绪准备运行时, 变为就绪状态\nReady → Running：处于就绪态的进程被进程调度程序选中后, 就分配到处理机上来运行\nRunning → Exit：当进程表示它已经完成或者因出错, 当前运行进程会由操作系统作结束处理\nRunning → Ready：处于运行状态的进程在其运行过程中, 由于分配它的处理机时间片用完而让出处理机（OS完成）\nRunning → Blocked：当进程请求某样东西且必须等待时（等待定时器的到达，等待读写文件…）\nBlocked → Ready：当进程要等待某事件到来时, 它从阻塞状态变到就绪状态\n进程挂起合理且充分低利用系统资源\n进程在挂起状态时, 意味着进程没有占用内存空间, 处在挂起状态的进程映像在磁盘上（把进程放到磁盘上）\n挂起状态\n阻塞挂起状态：进程在外存并等待某事件的出现\n就绪挂起状态：进程在外存，但只要进入内存，即可运行\n与挂起相关的状态转换\n挂起：把一个进程从内存转到外存；可能有一下集中情况：\n\n阻塞到阻塞挂起：没有进程处于就绪状态或就绪进程要求更多内存资源时，会进行这种转换，以提交新进程或运行时就绪进程\n就绪到就绪挂起：当有高优先级阻塞（系统认为会很快就绪的）进程和低优先级就绪进程时，系统会选择挂起低优先级就绪进程\n运行到就绪挂起：对抢先式分时系统，当有高优先级阻塞挂起进程因事件出现而进入就绪挂起时，系统可能会把运行进程转导就绪挂起状态\n\n在外存时的状态转换：\n\n阻塞挂起到就绪挂起：当有阻塞挂起进程因相关事件出现时，系统会把阻塞挂起进程转换为就绪挂起进程\n\n解挂/激活：把一个进程从外存转到内存；可能有一下几种情况：\n\n就绪挂起到就绪：没有就绪进程或挂起就绪进程优先级高于就绪进程时，会进行这种转换\n阻塞挂起到阻塞：当一个进程释放足够内存时，系统会把一个高优先级阻塞挂起（系统认为会很快出现所等待的事件）进程转换为阻塞进程\n\n状态队列\n\n由操作系统来维护一组队列，用来表示系统当中所有进程的当前状态\n不同的状态分别用不同的队列来表示（就绪队列, 各种类型的阻塞队列）\n每个进程的PCB都根据它的状态加入到相应的队列当中，当一个进程的状态发生变化时，它的PCB从一个状态中脱离出来，加入到另外一个队列\n\n7.8-7.10 线程为什么使用线程【案例】编写一个MP3播放软件\n核心功能模块有三个：\n\n从MP3音频文件当中读取数据；\n对数据进行压缩；\n把解压缩后的音频数据播放出来\n\n//单进程方式while(TRUE)&#123;\tRead();// I/O\tDecompress();// CPU\tPlay();&#125;//问题: 播放出来的声音能否连贯? 各个函数之间不是并发执行, 影响资源的使用效率//多进程方式//进程1while(TRUE)&#123;\tRead();&#125;//进程2while(TRUE)&#123;\tDecompress();&#125;//进程3while(TRUE)&#123;\tPlay();&#125;//问题: 进程之间如何通信,共享数据?另外,维护进程的系统开销较大://创建进程时,分配资源,建立PCB;撤销进程时,回收资源,撤销PCB;进程切换时,保存当前进程的状态信息\n\n需要提出一种新的实体，满足一下特性：\n\n实体之间可以并发地执行\n实体之间共享相同的地址空间\n\n什么是线程Thread：\n\n进程当中的一条执行流程\n从两个方面重新理解进程：\n从资源组合的角度：进程把一组相关的资源组合起来，构成了一个资源平台（环境），包括地址空间（代码段，数据段），打开的文件等各种资源\n从运行的角度：代码在这个资源平台上的一条执行流程（线程）\n\n\n\n线程=进程—共享资源\n线程的优点：\n\n一个进程中可以同时存在多个线程;\n各个线程之间可以并发地执行;\n各个线程之间可以共享地址空间和文件等资源\n\n线程的缺点：\n\n一个线程崩溃，会导致其所属进程的所有线程崩溃（给它了”权限”就得有更高的”责任”）\n\n进程所需的资源：\n不同的线程需要独立的寄存器和堆栈，共享代码，数据和文件等\n线程与进程的比较\n\n进程是资源分配单位，线程是CPU调度单位\n进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈\n线程同样具有就绪，阻塞和执行三种基本状态，同样具有状态之间的转换关系\n线程能减少并发执行的时间和空间开销：\n线程的创建时间比进程短；（直接利用所属进程的一些状态信息）\n线程的终止时间比进程短；（不需要考虑把这些状态信息给释放）\n同一进程内的线程切换时间比进程短；（同一进程不同线程的切换不需要切换页表）\n由于同一进程的各线程之间共享内存和文件资源，可直接进行不通过内核的通信。（直接通过内存地址读写资源）\n\n\n\n线程的实现主要有三种线程的实现方式\n\n用户线程：在用户空间实现；POSIX Pthreads，Mach C-threads, Solaris threads\n内核线程：在内核中实现；Windows，Solaris，Linux\n轻量级进程：在内核中实现，支持用户线程；Solaris\n\n用户线程与内核线程的对应关系\n\n多对一，一对一，多对多\n\n用户线程在用户空间实现的线程机制, 它不依赖于操作系统的内核, 由一组用户级的线程库来完成线程的管理, 包括进程的创建,终止,同步和调度等\n\n由于用户线程的维护由相应的进程来完成（通过线程库函数），不需要操作系统内核了解用户进程的存在，可用于不支持线程技术的多进程操作系统；\n每个进程都需要它自己私有的线程控制块（TCB）列表，用来跟踪记录它的各个线程的状态信息（PC，栈指针，寄存器），TCB由线程库函数来维护；\n用户线程的切换也是由线程库函数来完成，无需用户态/核心态切换，所以速度特别快；\n允许每个进程拥有自定义的线程调度算法.\n\n用户线程缺点：\n\n阻塞性的系统调用如何实现？如果一个线程发起系统调用而阻塞，则整个进程在等待；（操作系统看不到线程）\n当一个线程开始运行时，除非它主动地交出CPU的使用权，否则它所在的进程当中的其他线程将无法运行；（用户态线程库无法主动打断当前用户线程的执行）\n由于时间片分配给进程，所以与其他进程比,在多线程执行时，每个线程得到的时间片较少，执行会较慢\n\n内核线程内核线程是在操作系统的内核当中实现的一种线程机制，由操作系统的内核来完成线程的创建,终止和管理\n\n在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息（PCB和TCB）；\n线程的创建,终止和切换都是通过系统调用，内核函数的方式来进行，由内核来完成,因此系统开销较大；\n在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；\n时间片分配给线程，多线程的进程获得更多CPU时间；\nWindows NT 和 Windows 2000/XP 支持内核线程\n\n轻量级线程\n它是内核支持的用户线程。一个进程可以有一个或多个轻量化进程，每个量级进程由一个单独的内核线程来支持。（Solaris，Linux）\n7.11 上下文切换停止当前运行进程（从运行状态改变其他状态）并且调度其他进程（转变成运行状态）\n\n必须在切换之前存储许多部分的进程上下文\n必须能够在之后恢复他们,所以进程不能显示它曾经被暂停过\n必须快速（上下文切换时非常频繁）\n\n需要存储什么上下文？\n\n寄存器（PC，SP…），CPU状态等信息\n一些时候可能会费时,所以我们应该尽可能避免\n\n操作系统为活跃进程准备了进程控制块\n操作系统将进程控制块放置在一个合适的队列中\n\n就绪队列\n等待I/O队列（每个设备的队列）\n僵尸队列\n\n7.12-7.14 进程的控制创建进程fork（）的简单实现\n\n对子进程分配内存\n复制父进程的内存和CPU寄存器到子进程\n开销昂贵\n\n在99%的情况下,我们在调用fork()之后调用exec()\n\n在fork()操作中内存复制是没有作用的\n子进程将可能关闭打开的文件和连接\n开销因此是最高的\n为什么不能结合它们在一个调用中(OS/2, windows)?\n\nvfork（）\n\n一个创建进程的系统调用,不需要创建一个同样的内存映像\n一些时候称为轻量级fork（）\n子进程应该几乎立即调用exec（）\n现在不再使用如果我们使用 copy on write 技术\n\n加载和执行进程\n系统调用exec()加载程序取代当前运行的进程\n\nexec()调用允许一个进程”加载”一个不同的程序并且在main开始执行(事实上 _start)\n\n它允许一个进程指定参数的数量(argc)和它字符串参数数组(argv)\n\n如果调用成功(相同的进程,不同的程序)\n\n代码,stack,heap重写\n\n\n等待和终止进程wait()系统调用是被父进程用来等待子进程的结束\n\n一个子进程向父进程返回一个值,所以父进程必须接受这个值并处理\n\nwait（）系统调用担任这个要求\n\n它使父进程去睡眠来等待子进程的结束\n当一个子进程调用exit（）的时候，操作系统解锁父进程，并且将通过exit（）传递得到的返回值作为wait调用的一个结果（连同子进程的pid一起）如果这里没有子进程存活，wait（）立刻返回\n当然,如果这里有为父进程的僵尸等待，wait（）立即返回其中一个值（并且解除僵尸状态）\n\n\n进程结束执行之后，它调用exit（）\n\n这个系统调用：\n\n将这程序的”结果”作为一个参数\n关闭所有打开的文件,连接等等\n释放内存\n释放大部分支持进程的操作系统结构\n检查是否父进程是存活着的：\n如果是的话,它保留结果的值直到父进程需要它;在这种情况里,进程没有真正死亡,但是它进入了僵尸状态\n如果没有,它释放所有的数据结构,这个进程死亡\n\n\n清理所有等待的僵尸进程\n\n\n进程终止是最终的垃圾收集（资源回收）\n\n\n\n","categories":["操作系统"],"tags":["进程线程"]},{"title":"第九章 同步互斥","url":"/2021/11/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter9%E5%90%8C%E6%AD%A5%E4%BA%92%E6%96%A5/","content":"第九章 同步互斥9.1 背景到目前为止\n\n多道程序设计: 现代操作系统的重要特性\n并行很有用(为什么?) 提示: 多个并发实体: CPU IO 用户 等\n进程,线程: 操作系统抽象出来用于支持多道程序设计\nCPU调度: 实现多道程序设计的机制\n调度算法: 不同的策略\n\n独立的线程：\n\n不和其他线程共享资源或状态\n确定性: 输入状态决定结果\n可重现: 能够重现起始条件，I/O\n调度顺序不重要\n\n合作的线程：\n\n在多个线程中共享状态\n不确定性\n不可重现\n\n不确定性和不可重现意味着bug可能是间歇性发生的\n进程/线程，计算机/设备需要合作\n优点1：共享资源\n\n一台电脑，多个用户\n一个银行存款余额，多台ATM机\n嵌入式系统（机器人控制：手臂和手的协调）\n\n优点2：加速\n\nI/O操作和计算机可以重写\n多处理器-将程序分成多个部分并执行\n\n优点3：模块化\n\n将大程序分解成小程序\n使系统易于扩展\n\n程序可以调用函数fork（）来创建一个新的进程\n\n操作系统需要分配一个新的并且唯一的进程ID\n\n因此在内核中，这个系统调用会运行\n\nnew_pid=next_pid++;\n\n\n翻译成机器指令\n\nLOAD next_pid Reg1\nSTORE Reg1 new_pid\nINC Reg1\nSTORE Reg1 next_pid\n\n\n\n假如两个进程并发执行\n\n如果next_pid等于100，那么其中一个进程得到的ID应该是100，另一个进程的ID应该是101，next_pid应该增加到102\n\n可能在INC前进行了上下文切换, 最终导致两个进程的pid都是100，而next_pid也是101\n\n\n9.2-9.4 概念前面的现象称为Race Condition(竞态条件)\n系统缺陷: 结果依赖于并发执行或者时间的顺序,时间\n\n不确定性\n不可重视\n\nAtomic Operator(原子操作)\n原子操作是指一次不存在任何终端或者失败的执行\n\n该执行成功结束\n或者根本没有执行\n并且不应发生任何部分执行的状态\n\n实际上操作往往不是原子的\n\n有些看上去是原子操作,实际上不是\n连x++这样的简单语句,实际上是由三条指令构成的\n有时候甚至连单条假期指令都不是原子的\n\n)\nCritical section（临界区）：进程中的一段需要访问共享资源并且当另一个进程处于相应代码区域时便不会被执行的代码区域\nMutual exclusion（互斥）：当一个进程处于临界区并访问共享资源时，没有其他进程会处于临界区并且访问任何相同的共享资源\nDead lock（死锁）：是指两个或以上进程，在相互等待完成特定任务，而最终没法将自身任务进行下去\nStarvation（饥饿）：一个可执行的进程，被调度器持续忽略，以至于虽然处于可执行状态却不被执行\n\n9.5 临界区互斥：同一时间临界区中最多存在一个线程\nProgress：如果一个线程想要进入临界区，那么它最终会成功\n有限等待：如果一个线程i处于入口区，那么在i的请求被接受之前，其他线程进入临界区的时间是有限制的（如果无线等待，则会进入饥饿）\n无忙等待（可选）：如果一个进程在等待进入临界区，那么在它可以进入之前会被挂起\n9.6 方法一 禁用硬件中断没有中断，没有上下文切换，因此没有并发\n\n硬件将中断处理延迟到中断被启用之后\n大多数现代计算机体系结构都提供指令来完成\n\n进入临界区\n\n禁用中断\n\n离开临界区\n\n开启中断\n\n一旦中断被禁用，线程就无法被停止\n\n整个系统都会为你停下来\n可能导致七天线程处于饥饿状态\n\n要是临界区可以任意长怎么办\n\n无法限制响应中断所需的时间（可能存在硬件影响）\n\n要小心使用\n简单有效，受制于临界区时间，整个系统效率会产生很大影响，不太适合于多CPU\n9.7 方法2 基于软件的解决方法满足进程Pi和Pj之间互斥的经典的基于软件的解决方法(1981年)\n\n使用两个共享数据项\nint turn；//指示该谁进入临界区\nboolean flag[]；//指示进程是否准备好进入临界区\n\n进入临界区\n\n\nflag[i] = TRUE;turn = j;while(flag[j] &amp;&amp; turn==j);\n\n\n退出临界区\n\nflag[i]=FALSE;\n\n进程pi的算法：\ndo&#123;\tflag[i] = true;\tturn = j;\twhile(flag[j] &amp;&amp; turn == j);\t\tCRITICAL SECTION\tflag[i] = false;\t\tREMAINDER SECTION&#125;while(true);\n\nBakery 算法(N个进程的临界区)\n\n进入临界区之前,进程接收一个数字\n得到的数字最小的进入临界区\n如果进程Pi和Pj收到相同的数字,那么如果i&lt;j,Pi先进入临界区,否则Pj先进入临界区\n编号方案总是按照枚举的增加顺序生成数字\n\n复杂\n\n需要两个进程的共享数据项\n\n需要忙等待\n\n浪费CPU时间\n\n没有硬件保证的情况下无真正的软件解决方案\n\nPerterson算法需要原子的LOAD和STORE指令\n\n软件方法的开销与实现复杂性较大\n9.8 方法3 更高级的抽象硬件提供了一些原语\n\n像中断禁用，原子操作指令等\n大多数现代体系结构都这样\n\n操作系统提供更高级的编程抽象来简化并行编程\n\n例如：锁，信号量\n从硬件原语中构建\n\n锁是一个抽象的数据结构\n\n一个二进制状态（锁定/解锁），两种办法\nLock::Acquire() — 锁被释放前一直等待，然后得到锁\nLock::Release() — 释放锁，唤醒任何等待的进程\n\n使用锁来编写临界区\nlock_next_pid-&gt;Acquire();new_pid = next_pid++;lock_next_pid-&gt;Release();\n\n大多数现代体系结构都提供特殊的原子操作指令\n\n通过特殊的内存访问电路\n针对单处理器和多处理器\n\nTest-and-Set 测试和置位\n\n从内存中读取值\n测试该值是否为1（然后返回真或假）\n内存值设置为1\n\n交换\n\n交换内存中的两个值\n\nboolean TestandSet(boolean *target)&#123;\t\tboolean rv = *target;\t\t*target = true;\t\treturn rv;&#125;void Exchange(boolean *a, boolean *b)&#123;\t\tboolean tmp = *a;\t\t*a = *b;\t\t*b = tmp;&#125;\n\n采取基于原子操作的机器指令方式：\n\n优点：\n\n适用于单处理器或者共享主存的多处理器中任意数量的进程\n简单并且容易证明\n可以用于支持多临界区\n\n\n缺点：\n\n忙等待消耗处理器时间\n当进程离开临界区并且多个进程在等待的时候可能导致饥饿\n死锁：如果一个低优先级的进程拥有临界区并且一个高优先级进程也需求，那么高优先级进程会获得处理器并等待临界区\n\n\n\n总结\n锁是更高等级的编程抽象\n\n互斥可以使用锁来实现\n通常需要一个等级的硬件支持\n\n\n常用的三种实现方法\n\n禁用中断（仅限于单处理器）\n软件方法（复杂）\n原子操作指令（单处理器或多处理器均可）\n\n\n可选的实现内容：\n\n有忙等待\n无忙等待\n\n\n\n","categories":["操作系统"],"tags":["同步互斥"]},{"title":"二叉树搜索树","url":"/2021/12/08/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/","content":"二叉搜索树概述二叉树结构可以认为是二维的列表(列表在维度上的扩充)\n二叉搜索树在形式上继承了二叉树(列表结构的特点)，同时也巧妙的借鉴了有序向量的特点和优势(一种质的提高)\n循关键码访问\n数据项之间，依照各自的关键码彼此区分\n条件：关键码之间支持大小比较与想等比对\n数据集合中的数据项，统一地表示和实现为词条entry形式\n\n词条emplate &lt;typename K, typename V&gt; struct Entry &#123; //词条模板类   K key; V value; //关键码、数值   Entry ( K k = K(), V v = V() ) : key ( k ), value ( v ) &#123;&#125;; //默认构造函数   Entry ( Entry&lt;K, V&gt; const&amp; e ) : key ( e.key ), value ( e.value ) &#123;&#125;; //基于克隆的构造函数   bool operator&lt; ( Entry&lt;K, V&gt; const&amp; e ) &#123; return key &lt;  e.key; &#125;  //比较器：小于   bool operator&gt; ( Entry&lt;K, V&gt; const&amp; e ) &#123; return key &gt;  e.key; &#125;  //比较器：大于   bool operator== ( Entry&lt;K, V&gt; const&amp; e ) &#123; return key == e.key; &#125; //判等器：等于   bool operator!= ( Entry&lt;K, V&gt; const&amp; e ) &#123; return key != e.key; &#125; //判等器：不等于&#125;; //得益于比较器和判等器，从此往后，不必严格区分词条及其对应的关键码\n\n有序性\n局部性的特征\n\nBST(二叉搜索树)：节点词条关键码\n顺序性：任一节点均不小于/不大于其左/右后代\n只含单个节点或即便只含单分支，都可以称作BST\n单调性BST的中序遍历序列，必然单调非降\n这一性质，也是BST的充要条件\n\n所有节点的垂直投影所构成的序列即是中序序列\n在微观上处处满足顺序性，在宏观上整体满足单调性\n接口template &lt;typename T&gt; class BST : public BinTree&lt;T&gt; &#123; //由BinTree派生BST模板类protected:   BinNodePosi&lt;T&gt; _hot; //“命中”节点的父亲   BinNodePosi&lt;T&gt; connect34 ( //按照“3 + 4”结构，联接3个节点及四棵子树      BinNodePosi&lt;T&gt;, BinNodePosi&lt;T&gt;, BinNodePosi&lt;T&gt;,      BinNodePosi&lt;T&gt;, BinNodePosi&lt;T&gt;, BinNodePosi&lt;T&gt;, BinNodePosi&lt;T&gt; );   BinNodePosi&lt;T&gt; rotateAt ( BinNodePosi&lt;T&gt; x ); //对x及其父亲、祖父做统一旋转调整public: //基本接口：以virtual修饰，强制要求所有派生类（BST变种）根据各自的规则对其重写   virtual BinNodePosi&lt;T&gt; &amp; search ( const T&amp; e ); //查找   virtual BinNodePosi&lt;T&gt; insert ( const T&amp; e ); //插入   virtual bool remove ( const T&amp; e ); //删除   /*DSA*/   /*DSA*/void stretchToLPath() &#123; stretchByZag ( _root ); &#125; //借助zag旋转，转化为左向单链   /*DSA*/void stretchToRPath() &#123; stretchByZig ( _root ); &#125; //借助zig旋转，转化为右向单链   /*DSA*/void stretch();&#125;;\n\n查找\n减而治之：从根节点出发，逐步地缩小查找范围，直到发现目标(成功)，或查找范围缩小至空树(失败)\n对照中序遍历序列可见，整个过程可视作是在仿效有序向量的二分查找\ntemplate &lt;typename T&gt; BinNodePosi(T) &amp; BST&lt;T&gt;::search(const T &amp; e)&#123;return searchIn( _root,e,_hot = NULL);&#125; //从根节点启动查找static BinNodePosi(T) &amp; searchIn(    BinNodePosi(T) &amp; v,//当前(子)树根    const T &amp; e, //目标关键码    BinNodePosi(T) &amp; hot) //记忆热点&#123;    if (!v || (e == v-&gt;data)) return v; //足以确定失败，成功，或者    hot = v; //先记下当前(非空)节点，然后再...    return searchIn(((e &lt; v-&gt;data) ? v-&gt;lChild : v-&gt;rChild),e,hot);&#125; //运行时间正比于返回节点v的深度，不超过树高O(h)\n\n\n插入\ntemplate &lt;typename T&gt; BinNodePosi&lt;T&gt; BST&lt;T&gt;::insert ( const T&amp; e ) &#123; //将关键码e插入BST树中BinNodePosi&lt;T&gt; &amp; x = search ( e );   if ( x ) return x; //确认目标不存在（留意对_hot的设置）    x = new BinNode&lt;T&gt; ( e, _hot ); //创建新节点x：以e为关键码，以_hot为父\t_size++; //更新全树规模\tupdateHeightAbove ( x ); //更新x及其历代祖先的高度   return x; //新插入的节点，必为叶子&#125; //无论e是否存在于原树中，返回时总有x-&gt;data == e\n\n删除template &lt;typename T&gt; bool BST&lt;T&gt;::remove ( const T&amp; e ) &#123; //从BST树中删除关键码e   BinNodePosi&lt;T&gt; &amp; x = search ( e ); if ( !x ) return false; //确认目标存在（留意_hot的设置）   removeAt ( x, _hot ); _size--; //实施删除   updateHeightAbove ( _hot ); //更新_hot及其历代祖先的高度   return true;&#125; //删除成功与否，由返回值指示\n\ntemplate &lt;typename T&gt;static BinNodePosi&lt;T&gt; removeAt ( BinNodePosi&lt;T&gt; &amp; x, BinNodePosi&lt;T&gt; &amp; hot ) &#123;   BinNodePosi&lt;T&gt; w = x; //实际被摘除的节点，初值同x   BinNodePosi&lt;T&gt; succ = NULL; //实际被删除节点的接替者   if ( !HasLChild ( *x ) ) //若*x的左子树为空，则可      succ = x = x-&gt;rc; //直接将*x替换为其右子树   else if ( !HasRChild ( *x ) ) //若右子树为空，则可      succ = x = x-&gt;lc; //对称地处理——注意：此时succ != NULL   else &#123; //若左右子树均存在，则选择x的直接后继作为实际被摘除节点，为此需要      w = w-&gt;succ(); //（在右子树中）找到*x的直接后继*w      swap ( x-&gt;data, w-&gt;data ); //交换*x和*w的数据元素      BinNodePosi&lt;T&gt; u = w-&gt;parent;      ( ( u == x ) ? u-&gt;rc : u-&gt;lc ) = succ = w-&gt;rc; //隔离节点*w   &#125;   hot = w-&gt;parent; //记录实际被删除节点的父亲   if ( succ ) succ-&gt;parent = hot; //并将被删除节点的接替者与hot相联   release ( w-&gt;data ); release ( w ); return succ; //释放被摘除节点，返回接替者&#125; //release()负责释放复杂结构，与算法无直接关系，具体实现详见代码包\n\n平衡极短退化：当BST中所有节点的度数都不超过1，实际上已经退化成一条单链，此时整棵树的高度与整棵树的节点个数成线性正比关系(h=n-1)，这种情况下，最坏和平均意义都需要O(n)的时间\n平均高度\n随机生成的统一口径：当关键码总数为n时，可能的排列为n!棵，平均高度为logn，会出现冗余\n随机组成：将所有n个关键码视作n个互异的积木，所有BST的平均高度值为根号n\n中位数或是越接近与中位数的关键码，越是更早的插入，这类BST的高度会更低\n理想+适度什么样的树高度相对会更低\n\n节点数目固定时，兄弟子树高度越接近(平衡)，全树也将倾向于更低\n\n由n个节点组成的二叉树，高度不低于[ log2n]，恰为log2n时，称作理想平衡\n\n这样一种树在实际应用中是可遇不可求的，即便BST在某一时刻能够达到，在接下来的动态操作中，这样的高度也难以持续，因此所谓的理想平衡在实际意义中是不具任何意义的\n\n\n理想平衡出现概率极低，维护成本过高，故须适当地放松标准\n\n退一步海阔天空：高度渐进地不超过O(logn)，即称作适度平衡\n\n适度平衡BST，称作平衡二叉搜索树(BBST)\n\n\n歧义=等价\n相互等价的BST：两组BST的中序遍历序列完全一样，而拓扑却不尽相同\n\n上下可变：联接关系不尽相同，承袭关系可能颠倒，如19和16可以交换\n左右不乱：中序遍历序列完全一致，全局单调非降\n\n等价交换\n遵循两大准则\n\n局部性：执行的每一次等价变换，都应该局限在某一常数规模的局部(v和c)\n在将一棵刚刚失衡的BBST重新恢复于BST的过程中，累计需要执行的操作次数不要过多，至多不超过O(logn)\n\n","categories":["数据结构"],"tags":["数据结构与算法"]},{"title":"二叉树","url":"/2021/12/06/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E4%BA%8C%E5%8F%89%E6%A0%91/","content":"二叉树树无论是向量还是列表都无法做到兼顾静态和动态的高效\n半线性结构：树型结构不是狭义的线性结构，却带有线性的特征\n\n树是按照层次关系来组织数据项的方式\n\n有根树：r树根（父亲），subtree子树，ri之间互称兄弟（sibling），d = degree（r)为r的度，e树的边数，n顶点总数\n\n故在衡量相关复杂度时，可以n作为参照\n若指定Ti作为T的第i棵子树，ri作为r的第i个孩子，则T称作有序树(ordered tree)\n路径+环路\n连通+无环\n一旦指定了根，其他的节点都将获得一个确定的指标，通过指标，同一类顶点所具有的指标都是相等的，也称为等价类\n深度+层次\n根节点是所有节点的公共祖先，深度为0\n没有后代的节点称作叶子（leaf）\n所有叶子深度中的最大者，称作树的高度\n一个节点都没有的树称作空树，高度为-1\ndepth(v) + height(v) &lt;= height(T)\n树的表示\n性能：\n\n长子+兄弟每个节点均设两个引用\n纵：firstChild（）\n横：nextSibling（）\n\n二叉树节点度数不超过2的树称作二叉树（binary tree）\n同一节点的孩子和子树，均以左、右区分\n在有根性和有序性能够保证的前提下，二叉树足以描述所有的树\n\n深度为k的节点，至多为2^k个\n\n含n个节点，高度为h的二叉树中\nh &lt; n &lt; 2^h+1\n\nn = h + 1时，退化为一条单链\n\nn = 2^h+1 - 1时，即所谓满二叉树（full binary tree）\n\n\n真二叉树每个节点的度数都是偶数\n假想添加：\n\n用长子兄弟法将多叉树转化为二叉树\n\n即可以用二叉树来表示任何一棵有根有序树\n正因如此，二叉树虽是树的特例，却可直接研究二叉树\n实现BinNode类\n每个节点通过引用指向其他节点，每个节点所占据的一个空间为一个位置\n#define BinNodePosi(T) BinNode&lt;T&gt;* //节点位置template&lt;typename T&gt; struct BinNode&#123;    BinNodePosi(T) parent,lChild,rChild; //父亲，孩子    T data; int height; int size(); //高度，子树规模    BinNodePosi(T) insertAsLc(T const &amp;); //作为左孩子插入新节点    BinNodePosi(T) insertAsRc(T const &amp;); //作为右孩子插入新节点    BinNodePosi(T) succ(); //(中序遍历意义下)当前节点的直接后继    template &lt;typename VST&gt; void travLevel( VST &amp; ); //子树层次遍历    template &lt;typename VST&gt; void travPre( VST &amp; ); //子树先序遍历    template &lt;typename VST&gt; void travIn( VST &amp; ); //子树中序遍历    template &lt;typename VST&gt; void travPost( VST &amp; ); //子树后序遍历&#125;\n\n接口实现\n传入参数e进行封装，并且将它作为当前节点的左/右孩子，接入所属树中\ntemplate&lt;typename T&gt; BinNodePosi(T)::insertAsLc(T const &amp; e)&#123; return l Child = new BinNode(e,this); &#125; //O(1)\n\nsize(后代总数，即以其为根的子树的规模)\ntemplate&lt;typename T&gt;int BinNode&lt;T&gt;::size()&#123;    int s = 1; //计入本身    if(lChild) s += lChild-&gt;size(); //递归计入左子树规模    if(rChild) s += rChild-&gt;size(); //递归计入右子树规模    return s;&#125; //O(n=size)\n\nBinTree模板类template&lt;typename T&gt; class BinTree&#123;protected:    int _size; //规模    BinNodePosi(T) _root; //根节点    virtual int updateHeight( BinNodePosi(T) x); //更新节点x的速度    void updateHeightAbove(BinNodePosi(T) x); //更新x即祖先的速度public:    int size() const &#123; return _size; &#125; //规模    bool empty() const &#123; return !_root; &#125; //判空    BinNodePosi(T) root() const &#123; return _root; &#125; //树根    /* ...子树接入、删除和分离接口...*/    /* ...遍历接口... */&#125;\n\n高度更新根节点高度为0，空树高度为-1\n一个节点的高度恰好等于左右孩子中的更大者+1\n定义一个新的等价意义上的高度，使得算法更为简便：\n#define stature(p) ( (p) ? (p)-&gt;height : -1)\n\ntemplate&lt;typename T&gt; //更新节点x高度，具体规则因树不同而异int BinTree&lt;T&gt;::updateHeight( BinNodePosi(T) x)&#123;    return x-&gt;height = 1 + max( stature( x-&gt;lChild ),stature( x-&gt;rChild ) );&#125; //此处采用常规二叉树规则，O(1)\n\n如果x的父节点存在，那么x的高度变化，则会连锁到父节点，祖父节点…，因此更新节点从x出发，向上逐层追溯它的历代祖先直到抵达根节点\ntemplate&lt;typename T&gt; //更新v及其历代祖先的高度void BinTree&lt;T&gt;::updateHeightAbove( BinNodePosi(T) x )&#123;    while(x) //可优化：一旦高度未变，即可终止    &#123; updateHeight(x); x = x-&gt;parent; &#125;&#125; //O( n = depth(x) )\n\n节点插入在一棵二叉树中，将某个新生成的节点，作为树中某一原本没有右孩子的节点的右孩子接入\n\ntemplate&lt;typename T&gt; BinNodePosi(T)BinTree&lt;T&gt;::insertAsRc( BinNodePosi(T) X,T const &amp; e )&#123;    _size++;    x-&gt;insertAsRc(e); //x祖先的高度可能增加，其余节点必要不变    updateHeightAbove(x);    return x-&gt;rChild;&#125;\n\n先序遍历遍历：按照某种次序访问树中各节点，每个节点被访问恰好一次\n先序：V-&gt;L-&gt;R        中序：L-&gt;V-&gt;R        后序：L-&gt;R-&gt;V\n先序遍历顺序：自上而下访问左侧链上的节点，再自下而上访问它们的右子树\ntemplate&lt;typename T,typename VST&gt;void traverse(BinNodePosi(T) x,VST &amp; visit)&#123; //递归实现    if(!x) return; //递归基的处理    visit( x-&gt;data );     traverse( x-&gt;lChild,visit );    traverse( x-&gt;rChild,visit );&#125; //T(n) = O(1) + T(a) + T(n-a-1) = O(n)\n\n这种算法只具有渐进的意义，在实际过程中，因为递归程序的实现机制，只能采用通用的方法，运行栈中每个递归实例都具有一帧，但是因为它们必须具有通用格式，所以并不能做到足够的小。因此，作为树算法的重要基石，遍历算法非常有必要从递归改写为迭代\n迭代实现(1)template&lt;typename T,typename VST&gt;void travPre_I1( BinNodePosi(T) x,VST &amp; visit)&#123;    Stack&lt;BinNodePosi(T)&gt; S; //辅助栈    if(x) S.push(x); //根节点入栈    while( !S.empty() )&#123; //在栈变空之前反复循环        x = S.pop();        visit( x-&gt;data ); //弹出并访问当前节点        if( HasRChild(*x) ) S.push(x-&gt;rChild); //右孩子先入后出        if( HasLchild(*x) ) S.push(x-&gt;lChild); //左孩子后入先出    &#125;&#125;\n\n所有的遍历算法都是先访问左孩子再访问右孩子，所以依据栈的特性，右孩子先入后出（后遍历）\n\n对于任何一根子树，我们都将起始于树根的总是沿着左侧孩子分支不断下行的这条链，称作当前这棵子树的左侧链\n\n首先自顶而下的依次访问左侧链上的沿途节点，再倒过来，自底而上地依次遍历各个层次上的右子树\n迭代实现(2)template&lt;typename T,typename VST&gt; //分摊(1)\t static void visitAlongLeftBranch(BinNodePosi(T) x,VST &amp; visit,Stack&lt;BinNodePosi&gt; &amp; s)&#123;    while(x)&#123;        visit( x-&gt;data ); //反复访问当前节点        S.push( x-&gt;rChild ); //右孩子入栈        x = x-&gt;lChild; //沿左侧链下行    &#125;&#125;\n\ntemplate&lt;typename T,typename VST&gt;void travPre_I2( BinNodePosi(T) x,VST &amp; visit )&#123;    Stack&lt;BinNodePosi(T)&gt;S; //辅助栈    while(true)&#123; //以右子树为单位，逐批访问节点        visitAlongLeftBranch( x,visit,S); //访问子树x的左侧链，右子树入栈缓冲        if( S.empty() ) break; //栈空即退出        x = S.pop(); //弹出下一子树的根    &#125;&#125;\n\n\n中序遍历思路递归：\ntemplate&lt;typename T,typename VST&gt;void traverse( BinNodePosi(T) x,VST &amp; visit )&#123;    if( !x ) return;    traverse( x-&gt;lChild,visit );    visit( x-&gt;data );    traverse( x-&gt;rChild,visit );&#125; //T(n) = T(a) + O(1) + T(n-a-1) = O(n)\n\n\n从根节点开始一直沿着左侧分支逐层向下直到末端\n因此整个中序遍历分解为在不同尺度下的一系列的对左侧分支的逐步处理\n\n\n从根出发沿左分支下行，直到最深的节点——它就是全局首先被访问者\n自上而下谦让，再自下而上访问\n\n实现template&lt;typename T&gt;static void goAlingLeftBranch( BinNodePosi(T) x,Stack&lt;BinNodePosi(T)&gt; &amp; S )&#123; while(x) &#123; S.push(x); x = x-&gt;lChild; &#125;&#125; //反复地入栈，沿左分支深入template&lt;typename T,typename v&gt; void travIn_I1( BinNodePosi(T) x,V&amp; visit )&#123;    Stack&lt;BinNodePosi(T)&gt; S; //辅助栈    while(true)&#123;        goAlongLeftBranch(x, S); //从当前节点出发，逐批入栈        if( S.empty() ) break; //直至所有节点处理完毕        x = S.pop(); //x的左子树或为空，或已遍历（等效于空），故可以        visit( x-&gt;data ); //立即访问之        x = x-&gt;rChild; //再转向其右子树(可能为空，需留意处理手法)    &#125;&#125;\n\n\n所有左侧链的长度集中在一起也就是O(n)\n每一个节点的入栈操作对应的是左侧链上的一步，因此左侧链的长度就是push的操作次数\n后序遍历递归：\ntemplate&lt;typename T,typename VST&gt;void traverse( BinNodePosi&lt;T&gt; x,VST &amp; visit )&#123;    if( !x ) return;    traverse( x-&gt;lc,visit );    traverse( x-&gt;rc,visit );    visit( x-&gt;data );&#125;\n\n\n\n从根出发下行，尽可能沿左分支，实不得已，才沿右分支\n最后一个节点，必是叶子，而且是按中序遍历次序最靠左者，也是递归版中visit()首次执行处\n\ntemplate&lt;typename T&gt;static void gotoleftmostleaf( Stack&lt;BinNodePosi&lt;T&gt;&gt; &amp; S)&#123;    while( BinNOdePosi&lt;T&gt; x = S.top() ) //自顶而下反复检查栈顶节点        if( HasLChild(*x) )&#123; //尽可能向左，在此之前            if( HasRChild(*x) ) //若有右孩子，则                S.push( x-&gt;rc ); //优先入栈            S.push( x-&gt;lc ); //然后转向左孩子        &#125;else //实不得已            S.push( x-&gt;rc ); //才转向右孩子    S.pop(); //返回之前，弹出栈顶的空节点&#125;\n\ntemplate&lt;typename T,typename VST&gt;void travPost_I( BinNodePosi&lt;T&gt; x,VST &amp; visit )&#123;    Stack&lt;BinNodePosi&lt;T&gt;&gt; S; //辅助栈    if(&#125;\n\n层次遍历在此前的三种遍历中，都是后代先于祖先访问，即逆序，为此，都会使用到栈\n而在层次遍历中，所有节点都将按照深度次序由高至低访问\ntemplate&lt;typename T&gt;template&lt;typename T&gt;void BinNode&lt;T&gt;::travLevel( VST &amp; visit)    Queue&lt;BinNodePosi(T) Q; //引入辅助队列\tQ.enqueue( this ); //根节点入队\twhile( !Q.empty() )&#123; //在队列再次清空之前，反复迭代        BinNodePosi(T) x = Q.dequeue(); //在取出队首节点        visit( x-&gt;data );         if( HasLChild(*x) ) Q.enqueue( x-&gt;lChild ); //左孩子入队        if( HasRChile(*x) ) Q.enqueue( x-&gt;rChild ); //右孩子入队    &#125;\n\n\nHuffman树无前缀冲突编码各自的叶子不会待在另一叶子的通路上\n\n编码成本相差一个bit，影响的是带宽，费用，成本等等\n\n之所以要平衡，是为了杜绝深度差够大，至少是2的瑕疵，一旦有这种瑕疵，就可以通过交换进行优化\n带权编码长度因为频度的不同\n\n根据频率高/低的(超)字符，应尽可能放在高/低处\n故此，通过适当的交换，同样可以缩短wald(T)\n\n编码算法贪婪策略：频率低的字符优先引入，位置亦更低\n为每个字符创建一棵单节点的树，组成森林F\n按照出现频率，对所有树排列\nwhile( F中的树不止一棵 )    取频率最小的两棵树：T1和T2    将它们合并成一棵新树T，并令：    \tlchild(T) = T1且rChild(T) = T2    \tw(root(T)) = w(root(t1)) + w(root(T2))\n\n构造编码书\n每次取最小两个数合并(贪心)，并慢慢成长\n \n编码表：遍历，先中后序都可以，因为都是深度优先\n解码：从根开始，走到叶子，打印字符，再重置到根循环\n","categories":["数据结构"],"tags":["数据结构与算法"]},{"title":"向量","url":"/2021/12/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%90%91%E9%87%8F/","content":"向量抽象数据类型=数据模型+定义在该模型上的一组操作\n数据结构 =基于某种特定语言，实现ADT的一整套算法\n向量ADT向量是数组的抽象与泛化，由一组元素按线性次序封装而成\n各元素与[0，n）内的秩（rank）一一对应（循秩访问）\n元素的类型不限于基本类型\n操作、管理维护更加简化、统一安全\n可更为便捷地参与复杂数据结构的定制与实现\n\n构造与析构http://dsa.cs.tsinghua.edu.cn/~deng/ds/src_link/vector/vector.h.htm\nusing Rank = int; //秩#define DEFAULT_CAPACITY  3 //默认的初始容量（实际应用中可设置为更大）template &lt;typename T&gt; class Vector &#123; //向量模板类protected:Rank _size; Rank _capacity;  T* _elem; //规模、容量、数据区void copyFrom ( T const* A, Rank lo, Rank hi ); //复制数组区间A[lo, hi)void expand(); //空间不足时扩容void shrink(); //装填因子过小时压缩bool bubble ( Rank lo, Rank hi ); //扫描交换void bubbleSort ( Rank lo, Rank hi ); //起泡排序算法Rank maxItem ( Rank lo, Rank hi ); //选取最大元素void selectionSort ( Rank lo, Rank hi ); //选择排序算法void merge ( Rank lo, Rank mi, Rank hi ); //归并算法void mergeSort ( Rank lo, Rank hi ); //归并排序算法void heapSort ( Rank lo, Rank hi ); //堆排序（稍后结合完全堆讲解）Rank partition ( Rank lo, Rank hi ); //轴点构造算法void quickSort ( Rank lo, Rank hi ); //快速排序算法void shellSort ( Rank lo, Rank hi ); //希尔排序算法public:// 构造函数Vector ( int c = DEFAULT_CAPACITY, Rank s = 0, T v = 0 ) //容量为c、规模为s、所有元素初始为v&#123; _elem = new T[_capacity = c]; for ( _size = 0; _size &lt; s; _elem[_size++] = v ); &#125; //s&lt;=cVector ( T const* A, Rank n ) &#123; copyFrom ( A, 0, n ); &#125; //数组整体复制Vector ( T const* A, Rank lo, Rank hi ) &#123; copyFrom ( A, lo, hi ); &#125; //区间Vector ( Vector&lt;T&gt; const&amp; V ) &#123; copyFrom ( V._elem, 0, V._size ); &#125; //向量整体复制Vector ( Vector&lt;T&gt; const&amp; V, Rank lo, Rank hi ) &#123; copyFrom ( V._elem, lo, hi ); &#125; //区间// 析构函数~Vector() &#123; delete [] _elem; &#125; //释放内部空间// 只读访问接口Rank size() const &#123; return _size; &#125; //规模bool empty() const &#123; return !_size; &#125; //判空Rank find ( T const&amp; e ) const &#123; return find ( e, 0, _size ); &#125; //无序向量整体查找Rank find ( T const&amp; e, Rank lo, Rank hi ) const; //无序向量区间查找Rank search ( T const&amp; e ) const //有序向量整体查找&#123; return ( 0 &gt;= _size ) ? -1 : search ( e, 0, _size ); &#125;Rank search ( T const&amp; e, Rank lo, Rank hi ) const; //有序向量区间查找// 可写访问接口T&amp; operator[] ( Rank r ); //重载下标操作符，可以类似于数组形式引用各元素const T&amp; operator[] ( Rank r ) const; //仅限于做右值的重载版本Vector&lt;T&gt; &amp; operator= ( Vector&lt;T&gt; const&amp; ); //重载赋值操作符，以便直接克隆向量T remove ( Rank r ); //删除秩为r的元素int remove ( Rank lo, Rank hi ); //删除秩在区间[lo, hi)之内的元素Rank insert ( Rank r, T const&amp; e ); //插入元素Rank insert ( T const&amp; e ) &#123; return insert ( _size, e ); &#125; //默认作为末元素插入void sort ( Rank lo, Rank hi ); //对[lo, hi)排序void sort() &#123; sort ( 0, _size ); &#125; //整体排序void unsort ( Rank lo, Rank hi ); //对[lo, hi)置乱void unsort() &#123; unsort ( 0, _size ); &#125; //整体置乱Rank deduplicate(); //无序去重Rank uniquify(); //有序去重// 遍历void traverse ( void (* ) ( T&amp; ) ); //遍历（使用函数指针，只读或局部性修改）template &lt;typename VST&gt; void traverse ( VST&amp; ); //遍历（使用函数对象，可全局性修改）&#125;; //Vector\n\n原理：\n\n向量的复制\ntemplate&lt;typename T&gt; //T为基本类型，或已重载赋值操作符&#x27;=&#x27;void vector&lt;T&gt;::copyFrom(T* const A,Rank lo,Rank hi)&#123;    _elem = new T[_capacity = 2*(hi-lo)]; //分配空间,预留出足够的空间，在接下去足够长的时间内，不必因为有必要的扩容而打断计算过程    _size = 0; //规模清零    while(lo&lt;hi) //A[lo,hi)内的元素逐一        _elem[size++] = A[lo++]; // 复制至_elem[0,hi-lo)&#125;\n\n\n可扩充向量若采用静态空间管理策略，容量_capacity固定，则有明显的不足\n\n上溢（overflow）：_elem[]不足以存放所有元素\n尽管此时系统仍有足够的空间\n\n下溢（underflow）：_elem[]中的元素寥寥无几\n装填因子（load factor）size/capacity &lt;&lt; 50% \n\n\n更糟糕的是，一般的应用环境中难以准确预测空间的需求量\n可否使得向量可随实际需求动态调整容量，并同事保证高效率？\n动态空间管理在即将发生上溢时，适当的扩大内部数组的容量\n\ntemplate&lt;typename T&gt;void vector&lt;T&gt;::expand()&#123;\t//向量空间不足时扩容    if(_size&lt;_capacity)return; //尚未满员，不必扩容    _capacity = max(_capacity,DEFAULT_CAPACITY); //不低于最小容量    T* oldElem = _elem;    _elem = new T[_capacity &lt;&lt;= 1]; //容量加倍    for(int i = 0;i &lt; _size; i++) //复制原向量内容        _elem[i] = oldElem[i]; //T为基本类型，或已重载赋值操作符&#x27;=&#x27;    delete[]oldElem; //释放原空间&#125;\n\n得益于向量的封装，尽管扩容之后的数据区的物理地址有所改变，却不致出现野指针\n递增式扩容T* oldElem = _elem; _elem = new T[_capacity += INCREMENT];//追加固定大小的容量\n\n最坏情况：在初始容量0的空向量中，连续插入n=m*I &gt;&gt; 2个元素…\n每一次的扩容与复制都会使得时间成本过多\n加倍式扩容T* oldElem = _elem; _elem = new T[_capacity &lt;&lt;= 1];//容量加倍\n\n在最坏去情况下，在初始容量为1的满向量中，连续插入n=2^m &gt;&gt; 2个元素\n各次扩容过程中复制原向量的时间成本依次为\n1,2,4,8，。。。，2^m = n  //几何级数\n总体耗时=O(n)，每次扩容的分摊成本为O(1)\n\n分摊复杂度平均复杂度或期望复杂度( average/expected complexity )\n\n根据数据结构各种操作出现概率的分布，将对应的成本加权平均\n\n各种可能的操作，作为独立事件分别考查\n\n割裂了操作之间的相关性和连贯性\n\n往往不能准确地评判数据结构和算法的真实性能\n\n\n分摊复杂度( amortized complexity )\n\n对数据结构连续地实施足够多次操作,所需总体成本分摊至单次操作\n从实际可行的角度,对一系列操作做整体的考量\n更加忠实地刻画了可能出现的操作序列\n可以更为精准地评判数据结构和算法的真实性能\n\n无序向量循秩访问从便捷性出发，实现和数组元素访问方式一样的：A[r]\n因此，重载下标操作符“[]”\ntemplate&lt;typename T&gt; //0 &lt;= r &lt; _sizeT &amp; vector&lt;T&gt;::operator[](Rank r) const &#123; return _elem[r]; &#125;\n\n右值：T x = v[r] + U[s] * W[t];\n左值：v[r] = (T)(2*X+3); //因为是引用的方式，所以可以为左值\n插入因为所有的向量元素都是紧邻排序的，所以为了能够插入新的元素，就必须将新元素的后缀元素整体右移\ntemplate&lt;typename T&gt; //e作为秩为r元素插入，0&lt;=r&lt;=sizeRank vector&lt;T&gt;::insert(Rank r,T const &amp; e)&#123;//O(n-r)    expand(); //若有必要，扩容    for(int i = _size;i &gt; r;i--) //自后向前，如果次序颠倒，则有可能出现数据被覆盖的危险        _elem[i] = _elem[i-1]; //后继元素顺次后移一个单元    _elem[r] = e; _size++; //置入新元素，更新容量    return r; //返回秩&#125;\n\n\n删除删除后，后缀统一左移，自前向后的前移操作，若顺序颠倒，可能出现危险\ntemplate&lt;typename T&gt; //删除区间[lo,hi),0&lt;=lo&lt;=hi&lt;=sizeint vector&lt;T&gt;::remove(Rank lo,Rank hi)&#123;//O(n-hi)    if(lo==hi) return 0; //出于效率考虑，单独处理退化情况    while(hi&lt;_size)        _elem[lo++] = _elem[hi++]; //[hi,_size)顺次前移hi-lo位    _size = lo; shrink(); //更新规模，若有必要缩容    return hi-lo;&#125;\n\n\n单元素删除可以视作区间删除操作的特例：[r] = [r,r+1)\n template&lt;typename T&gt; //删除向量中秩为r的元素，0&lt;=r&lt;sizeT vector&lt;T&gt;::remove(Rank r)&#123; //O(n-r)    T e = _elem[r]; //备份被删除的元素    remove(r,r+1); //调用区间删除算法    return e; //返回被删除元素&#125;\n\n查找template&lt;typename T&gt; //0&lt;=lo&lt;hi&lt;=_sizeRank vector&lt;T&gt;::find(T const &amp; e,Rank lo,Rank hi)const&#123;//O(hi-lo)=O(n),在命中多个元素时可返回秩最大者   while((lo &lt; hi--)&amp;&amp;(e != _elem[hi])); //逆向查找    return hi; //hi&lt;lo意味着失败；否则hi即命中元素的秩&#125;\n\n输入敏感算法：最好O(1)，最差O(n)\n去重/唯一化应用实例：网络搜索的局部结果经过去重操作，汇总为最终报告\ntemplate &lt;typename T&gt; //删除重复元素，返回被删除元素数目int Vector&lt;T&gt;::deduplicate() &#123; //繁琐版+错误版   int oldSize = _size; //记录原规模   Rank i = 1; //从_elem[1]开始   while (i &lt; _size) //自前向后逐一考查各元素_elem[i]      if (find(_elem[i], 0, i) &lt; 0) //在前缀中寻找与之雷同者（至多一个）         i++; //若无雷同则继续考查其后继      else         remove(i); //否则删除当前元素（至多一个？）   return oldSize - _size; //被删除元素总数&#125;\n\n正确性：\n不变性：在当前元素 v[i] 的前缀 v[0,i] 中，各元素彼此互异\n单调性：随着反复的while迭代\n\n当前元素前缀的长度单调非降，且迟早增至_size \n当前元素后缀的长度单调下降，且迟早减至0\n\n故算法必然终止，且至多迭代O(n)轮\n\n复杂度：\n每轮迭代中 find() 和 remove() 累计耗费线性时间，故总体为O(n^2)\n遍历遍历向量，统一对各元素分别实施visit操作\n利用函数指针实例，只读或局部性修改\ntemplate&lt;typename T&gt;void vector&lt;T&gt;::traverse(void (*visit)(T&amp;)) //函数指针&#123;    for (int i = 0;i &lt; _size;i++)        visit(_elem[i]);&#125;\n\n利用函数对象机制，可全局性修改\ntemplate&lt;typename T&gt; template&lt;typename VST&gt;void vector&lt;T&gt;::traverse(VST&amp; visit) //函数对象&#123;    for (int i = 0;i &lt; _size;i++)        visit(_elem[i]);&#125;\n\n有序向量如何甄别一个向量是否有序\n有序/无序序列中，任意/总有一对相邻元素顺序/逆序\n因此，相邻逆序对的数目，可用以度量向量的逆序程度\ntemplate&lt;typename T&gt; //返回逆序相邻元素对的总数int vector&lt;T&gt;::disordered()const&#123;    int n = 0; //计数器    for(int i = 1;i &lt; _size;i++) //逐一检查各队相邻元素        n += (_elem[i - 1] &gt; _elem[i]); //逆序则计数    return n; //向量有序当且仅当 n = 0&#125; //若只判断是否有序，则首次遇到逆序对之后，即可立即终止\n\n唯一化低效版观察：在有序向量中，重复的元素必要相互紧邻构成一个区间，每一个区间只需保留单个元素即可\ntemplate&lt;typename T&gt;int vector&lt;T&gt;::uniquify()&#123;    int oldSize = _size;    int i = 0; //从首元素开始    while(i &lt; _size-1) //从前向后，逐一比对各对相邻元素，若雷同，则删除后者；否则，转至后一元素        (_elem[i] == _elem[i+1])?remove(i+1):i++;    return oldSize - _size; //向量规模变化量，即删除元素总数&#125; //注意：其中_size的减少，由remove()隐式地完成\n\n运行时间主要取决于while循环，次数共计： _size-1 = n-1\n最坏情况下：每次都需调用remove()，耗时O(n-1)~O(1)；累计O(n^2) \n\n高效版如果能够将每一个区间作为一个整体，成批的删除雷同元素，则有可能实现一步到位式移动\ntemplate&lt;typename T&gt;int vector&lt;T&gt;::uniquify()&#123;    Rank i = 0,j = 0; //各对互异“相邻”元素的秩    while(++j &lt; _size) //逐一扫描，直至末元素        //跳过雷同；发现不同元素时，向前移至紧邻于前者右侧        if(_elem[i] != _elem[j])            _elem[++i] = _elem[j];    _size = ++i;     shrink(); //直接删除尾部多余元素    return j - i; //向量规模变化量，即被删除元素总数&#125; //注意：通过remove(lo,hi)批量删除，依然不能达到高效率\n\n共计n-1次迭代，每次常数时间，累计O(n)时间\n\n二分查找（A)语义约定至少应该便于有序向量自身的维护：v.insert ( 1 + v.search(e) , e )\n即便失败，也应给出新元素适当的插入位置\n若允许重复元素，则每一组也需按其插入的次序排列\n\n约定：在有序向量区间v[lo , hi) 中，确定不大于e的最后一个元素秩\n若-无穷 &lt; e &lt; v[lo]，则返回lo - 1（左侧哨兵）\n若 v[hi-1] &lt; e &lt; +无穷，则返回 hi-1（末元素=右侧哨兵左邻）\n原理\n二分（折半）策略：轴点mi总是取作中点——于是\n每经过至多两次比较，或者能够命中，或者将问题规模缩减一半\n实现template&lt;typename T&gt; //在有序向量区间[lo,hi)内查找元素estatic Rank binSearch(T* A,T const&amp; e,Rank lo,Rank hi)&#123;    while(lo &lt; hi)    &#123;\tRank mi = (lo + hi)&gt;&gt;1; //以中点为轴点     \tif(e &lt; A[mi]) hi = mi; //目标处于e的左侧，深入前半段[lo,mi)继续查找    \telse if(A[mi] &lt; e) lo = mi + 1; //目标\t处于e的右侧，深入后半段(mi,hi)     \telse return mi; //在mi处命中    &#125;    return -1; //查找失败&#125;\n\n\n\nFib查找\n二分查找版本A的效率仍有改进余地，因为不难发现转向左、右分支前的关键吗比较次数不等，而递归深度却相同\n若能通过递归深度的不均衡，来转向成本的不均衡进行补偿，平均查找长度应能进一步缩短\n\n\ntemplate&lt;typename T&gt; //0 &lt;= lo &lt;=hi &lt;= _sizestatic Rank fibsearch(T* A,T const &amp; e,Rank lo,Rank hi)&#123;    Fib fib(hi-lo);    while(lo &lt; hi)    &#123;        while(hi - lo &lt; fib.get())            fib.prev(); //至多迭代几次？        //通过向前顺序查找，确定形如fib(k) - 1的轴点(分摊O(1))        Rank mi = lo + fib.get() - 1; //按黄金比例切分        if(e &lt; A[mi]) hi = mi; //深入前半段[lo,mi)继续查找        else if (A[mi] &lt; e)lo = mi + 1; //深入后半段(mi,hi)        else return mi; //在mi处命中    &#125;    return -1; //查找失败&#125;\n\n二分查找(B)每次迭代（或每个递归实例）仅做1次关键码比较，如此，所有分支只有2个方向，而不再是3个\n\n\n以上二分查找及Fibnacci查找算法\n均为严格地兑现search（）接口的语义约定：返回不大于e的最后一个元素\n\n只有兑现这一约定，才可有效支持相关算法，比如：v.insert（1+v.search（e），e）\n\n只有多个命中元素时，必须返回最靠后（秩最大）者\n失败时，应返回小于e的最大者（含哨兵[lo-1]）\n\n\n\ntemplate&lt;typename T&gt;static Rank binSearch(T* A,T const &amp; e,Rank lo,Rank hi)&#123;    while(1 &lt; hi - lo)    &#123;//有效查找区间的宽度缩短至1时，算法才会终止        Rank mi = (lo + hi) &gt;&gt; 1; //以中点为轴点，经比较后确定深入        （e &lt; A[mi]) ? hi = mi : lo = mi; //[lo,mi)或[mi,hi)    &#125; //出口时hi = lo + 1,查找区间仅含一个元素A[lo]    return (e == A[lo]) ? lo : -1; //返回命中元素的秩或者-1&#125; //相较于版本A，最好（坏）情况下更坏（好）；各种情况下的SL更加接近，整体性能更趋稳定\n\n\n二分查找（C）template&lt;typename T&gt;static Rank binSearch(T* A,T const &amp; e,Rank lo,Rank hi)&#123;    while(hi &lt; lo)    &#123;//不变性：A[0,lo) &lt;= e &lt; A[hi,n]        Rank mi = (lo + hi) &gt;&gt; 1; //以中点为轴点，经比较后确定深入        （e &lt; A[mi]) ? hi = mi : lo = mi + 1; //[lo,mi)或（mi,hi)    &#125; //出口时,A[lo = hi]为大于e的最小元素    return --lo; //故lo - 1即不大于e的元素的最大秩&#125;\n\n与版本B的差异\n\n待查找区间宽度缩短至0而非1时，算法才结束\n转入右侧子向量时，左边界取作mi+1而非mi\n无论成功与否，返回的秩严格符合接口的语义约定\n\n\n插值排序假设已知有序向量中各元素随机分布的规律，比如均匀且独立的随机分布\n那么[lo，hi）内各元素应大致按照线性趋势增长\n因此通过猜测轴点mi，可以极大提高收敛速度\n\n最坏情况：可能退化为平凡的顺序查找  O（hi - lo） = O（n）\n平均情况：每经一次比较，n缩至根号n\n\n\n易受小扰动的干扰和“蒙骗”\n\n须引入乘法、除法运算\n\n实际可行的方法\n首先通过插值查找，将查找范围缩小到一定的范围，然后再进行二分查找\n\n\n大规模：插值查找\n中规模：折半查找\n小规模：顺序查找\n起泡排序向量若有序排列，计算效率将大大提升\n如何实现向量的有序化？（排序算法）\n统一接口 sort（Rank lo，Rank hi）\ntemplate&lt;typename T&gt;void vector&lt;T&gt;::bubbleSort(Rank lo,Rank hi)&#123; while(!bubble(lo,hi--)); &#125; //逐趟做扫描交换，直至全序\n\n不变性：每经过对bubble的调用，都会有一个新的元素就位（减而治之），有序的部分逐渐拓展，无序的部分逐渐缩减\n\n改进：绿色的部分未必都是无序的，有可能存在一部分或者所有绿色都是有序的\n如何尽早判定这种情况？\n每一趟扫描交换，都记录下是否存在逆序元素，若存在，当且仅当做过交换\n反例\n实质需要排序的元素集中在一个宽度仅为根号n的区间中\n \n多余出来的消耗就是在后缀中已就位元素的扫描交换\n记录在上一趟扫描交换中所进行的最后一趟交换，就可以知道上一趟有多长的后缀没有进行扫描交换，如果这样，只需将右侧标志hi指向新的位置\ntemplate&lt;typename T&gt;void vector&lt;T&gt;::bubbleSort(Rank lo,Rank hi)&#123; while(lo &lt; (hi = bubble(lo,hi))); &#125; //逐趟做扫描交换，直至全序template&lt;typname T&gt;Rank vector&lt;T&gt;::bubble(Rank lo,Rank hi)&#123;    Rank last = lo; //最右侧的逆序对初始化为[lo - 1,lo]    while(++lo &lt; hi) //自左向右，逐一检查各队相邻元素        if(_elem[lo - 1] &gt; _elem[lo])        &#123;//若逆序，则更新最右侧逆序对位置记录，并交换         \tlast = lo;            swap(_elem[lo - 1],_elem[lo]);        &#125;    return last; //返回最右侧的逆序对位置&#125; \t\n\n归并排序\n序列一分为二，子序列递归排序，合并有序子序列\ntemplate&lt;typename T&gt;void vector&lt;T&gt;::mergeSort(Rank lo,Rank hi)&#123;    if(hi - lo &lt; 2) return; //单元素区间自然有序    int mi = (lo + hi) &gt;&gt; 1; //以中点为界    mergeSort(lo,mi); //对前半段排序    mergeSort(mi,hi); //对后半段排序    merge(lo,mi,hi); //归并&#125;\n\n二路归并\n\ntemplate&lt;typename T&gt;void vector&lt;T&gt;::merge(Rank lo,Rank mi,Rank hi)&#123;    T*A = _elem + lo; //合并后的向量A[0,hi - lo) = _elem[lo,hi)    int 1b = mi - lo;    T*B = new T[1b]; //前子向量B[0,1b) = _elem[lo,mi)    for(Rank i = 0;i &lt; 1b;B[i] = A[i++]); //复制前子向量B    int 1c = hi - mi;    T*C = _elem + mi; //后子向量C[0,1c) = _elem[mi,hi)    for(Rank i = 0,j = 0, k = 0;(j &lt; 1b) || (k &lt; 1c);)    &#123;//B[j]和C[k]中小者转至A的末尾        if((j &lt; 1b) &amp;&amp; (1c &lt;=k || (B[j] &lt;= C[k])))             A[i++] = B[j++]; //C[k]已无或不小        if((k &lt; 1c) &amp;&amp; (1b &lt;= j || (C[k] &lt; B[j])))            A[i++] = C[j++]; //B[j]已无或更大    &#125; //该循环实现紧凑；但就效率而言，不如拆分处理    delete[] B; &#125;\n\n\n\n\n一般B提前耗尽，就可终止算法\n复杂度\n算法的运行时间主要消耗与for循环，共有两个控制变量\n\n初始：j = 0，k = 0\n最终：j = lb，k = lc\n亦即：j + k = lb + lc = hi - lo = n\n\n每经过一次迭代，j和k中至少有一个会加一（j+k也必至少加一）\n故知：merge()总体迭代不过O(n)次，累计只需线性时间\n","categories":["数据结构"],"tags":["数据结构与算法"]},{"title":"列表","url":"/2021/12/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%88%97%E8%A1%A8/","content":"列表接口与实现根据是否修改数据结构，所有操作大致分为两类方式\n\n静态：仅读取，数据结构的内容及组成一般不变：get、search\n动态：需写入，数据结构的局部或整体将改变：insert、remove\n\n与操作方式相对应地，数据元素的存储与组织方式也分为两种\n\n静态：\n\n数据空间整体创建或销毁\n数据元素的物理存储次序与其逻辑次序严格一致\n可支持高效的静态操作\n比如向量，元素的物理地址与其逻辑次序线性对应\n\n\n动态：\n\n为各数据元素动态地分配和回收的物理空间\n逻辑上相邻的元素记录彼此的物理地址，在逻辑上形成一个整体\n可支持高效的动态操作\n\n\n\n从向量到列表列表（list）是采用动态存储策略的典型结构，其中的元素称作节点（node）\n各节点通过指针或引用彼此联接，在逻辑上构成一个线性序列\n相邻节点彼此互称前驱或后驱\n没有前后驱的唯一节点称作首（first/front）/末（last/rear）节点\n从秩到位置向量支持循秩访问的方式（这种方式效率高）\n然而在列表中，这种循秩访问的成本过高，已不合时宜\n因此，应该用循位置访问的方式，即利用节点之间的相互引用，找到特定的节点 \n\nADT接口\n\n列表节点类：\n#define Posi(T) ListNode&lt;T&gt;* //列表节点位置template&lt;typename T&gt;struct ListNode&#123; //列表节点模板类（以双向链表形式实现）    T data; //数值    Posi(T) pred; //前驱    Posi(T) succ; //后继    ListNode()&#123;&#125; //针对header和trailer的构造    ListNode(T e,Posi(T)p = NULL,Posi(T) s = NULL)        :data(e),pred(p),succ(s)&#123;&#125; //默认构造器    Posi(T) insertAsPred(T const&amp; e); //前插入    Posi(T) insertAsSucc(T const&amp; e); //后插入 &#125;;\n\n\n头、首、末、尾节点的秩可分别理解尾-1，0，n-1，n\n\n template&lt;typename T&gt; void List&lt;T&gt;::init()&#123;//初始化，创建列表对象时统一调用    header = new ListNode&lt;T&gt;; //创建头哨兵节点    trailer = new ListNode&lt;T&gt;; //创建尾哨兵节点    header-&gt;succ = trailer; header-&gt;pred = NULL; //互联    trailer-&gt;pred = header; trailer-&gt;succ = NULL; //互联    _size = 0; //记录规模&#125;\n\n无序列表插入template&lt;typename T&gt;Posi(T) List&lt;T&gt;::insertBefore(Posi(T)p,T const&amp; e)&#123; _size++; return p-&gt;insertAsPred(e); &#125;//e当做p的前驱插入\n\ntemplate&lt;typename T&gt; //前插入算法（后插入算法完全对称）Posi(T)ListNde&lt;T&gt;::insertAsPred(T const&amp; e)&#123;    Posi(T) x = new ListNode(e,pred,this); //创建（耗时一百倍）    pred-&gt;succ = x;    pred = x;    return x; //建立连接，返回新节点的位置&#125;\n\n即便当前节点是首节点，前驱依然是存在的（哨兵）\n\n基于复制的构造\ntemplate&lt;typename T&gt; //基本接口void List&lt;T&gt;::copyNodes(Posi(T) p,int n)&#123;    init(); //创建头、尾哨兵节点并做初始化    while(n--) //将起自p的n项依次作为末节点插入    &#123; insertAslast(p-&gt;data); p = p-&gt;succ; &#125;&#125;\n\n所谓insertAsLast其实就是insertBefore(trailer)\n删除与析构删除：\ntemplate&lt;typename T&gt; //删除合法位置p处节点，返回其数值T List&lt;T&gt;::remove(Pose(T) P)&#123; //O(1)    T e = p-&gt;data; //备份待删除节点数值（设类型T可直接赋值）    p-&gt;pred-&gt;succ = p-&gt;succ;    p-&gt;succ-&gt;pred = p-&gt;pred;    delete p;    _size--;    return e; //返回备份数值&#125;\n\n\n析构：\ntemplate&lt;typename T&gt; List&lt;T&gt;::~List()//列表析构&#123; clear(); delete header; delete trailer; &#125; //清空列表，释放头、尾\n\ntemplate&lt;typename T&gt; int List&lt;T&gt;::clear()&#123; //清空列表\tint oldSize = _size;    while(0 &lt; _size) //反复删除首节点，直至列表变空        remove(header-&gt;succ);    return oldSize;&#125; //O(n),线性正比于列表规模\n\n查找在节点p（可能是trailer）的n个（真）前驱中，找到等于e的最后者\ntemplate&lt;typename T&gt; //从外部调用时，0&lt;=n&lt;=rank(p)&lt;_sizePosi(T) List&lt;T&gt;::find(T const &amp;e,int n,Pose(T) p) const&#123; //顺序查找，O(n)    while(0 &lt; n--) //从右向左，逐个将p的前驱与e比对        if(e == (p = p-&gt;pred)-&gt;data)            return p; //直至命中或范围越界    return NULL; //若越出左边界，意味着查找失败&#125; \n\n如果目标节点有多个，那么会停止于最靠后的节点\n\n去重template&lt;typename T&gt; int List&lt;T&gt;::deduplicate()&#123; //剔除无序列表中重复的节点    if(_size &lt; 2) return 0; //平凡列表自然无重复    int oldSize = _size; //记录原规模    Pose(T) p = first(); rank r = 1; //p从首节点起    while(trailer != (p = p-&gt;succ))    &#123; //依次直到末节点        Posi(T) q = find(p-&gt;data,r,p); //在p的r个（真）前驱中，查找与之雷同者        q ? remove(q) : r++; //若的确存在，则删除；否则秩递增    &#125; //assert：循环过程中的任意时刻，p的所有前驱互不相同    return oldSize - _size; //列表规模变化量，即被删除元素总数&#125;\t\t\n\n有序列表唯一化\ntemplate&lt;typename T&gt; int List&lt;T&gt;::uniquify()&#123; //成批剔除重复元素    if(_size &lt; 2) return 0;    int oldSize = size;     ListNodePosi(T) p = first();    ListNodePosi(T) q; //p为各区段起点，q为其后继    while(trailer != (q = p-&gt;succ)) //反复考察紧邻的节点对（p，q）        if(p-&gt;data != q-&gt;data) p = q; //若互异，则转向下一区段    \telse remove(q);    return oldSize - _size; //被删除元素总数&#125; //只需遍历整个列表一趟，O(n)\n\n查找template&lt;typename T&gt; //在有序列表内节点p的n个（真）前驱中，找到不大于e的最后者Posi(T) List&lt;T&gt;::search(T const &amp;e,int n,posi(T) p) const&#123;    while(0 &lt;= n--) //对于p的最近的n个前驱，从右向左        if(((p = p-&gt;pred)-&gt;data) &lt;= e) break; //逐个比较   return p; //直至命中、数值越界或范围越界后，返回查找终止的位置&#125; //最好O(1)，最坏O(n);等概率时平均O(n),正比于区间宽度\n\nvector访问方式依据 rank 秩（RAM模型）\nList访问方式依据 Posi （TM模型）\n选择排序改进思路：相较于起泡排序的短距离小步慢跑式的挪动最大元素，为何不一次性完成这项工作\n\n//对列表中起始于位置p的连续n个元素做排序，valid（p） &amp;&amp; rank（p） + n &lt;= sizetemplate&lt;typname T&gt;void List&lt;T&gt;::selectionsort(Posi(T) p,int n)&#123;    Posi(T) head = p-&gt;pred;    Posi(T) tail = p; //待排序区间（head，tail）    for(int i = 0;i &lt; n;i++)         tail = tail -&gt; succ; //head/tail可能是头/尾哨兵    while(1 &lt; n)&#123;//反复从（非平凡的）待排序区间内找出最大者，并移至有序区间前端        insertBefore(tail,remove(selectMax(head-&gt;succ,n)));        tail = tail-&gt;pred;        n--; //待排序区间、有序区间的范围，均同步更新    &#125;&#125;\n\n\nselectMax（）\ntemplate&lt;typename T&gt; //从起始于位置p的n个元素中选出最大者，1 &lt; nPosi(T) List&lt;T&gt;::selectMax(Posi(T) P,int n)&#123; //O(n)    Posi(T) max = p; //最大者暂定为p    for(Posi(T) cur = p;1 &lt; n;n--) //后续节点逐一与max比较        if( !lt((cur = cur-&gt;succ)-&gt;data,max-&gt;data)) //若&gt;=max,则更新最大元素位置记录            max = cur;    return max;&#125;\n\n使用 &gt;= 可以对重复元素进行处理\n插入排序\n前缀部分总是有序直到整段有序\n//对列表中起始于位置p的连续n个元素做插入排序，valid(p) &amp;&amp; rank(p) + n &lt;= sizetemplate&lt;typename T&gt;void List&lt;T&gt;::insertionSort(Posi(T) p,int n)&#123;    for(int r = 0;r &lt; n;r++)&#123;        insertAfter(search(p-&gt;data,r,p),p-&gt;data); //查找+插入        p = p-&gt;succ;        remove(p-&gt;pred); //转向下一节点    &#125; //n次迭代，每次O(r+1)&#125; //仅使用O(1)辅助空间，属于就地算法\n\n\n最好情况：完全（或几乎）有序\n每次迭代，只需1次比较，0次交换，累计O(n)时间\n最坏情况：完全（或几乎）逆序\n第k次迭代，需O(k)次比较，1次交换，累计O(n^2)时间\n逆序对（inversion）某两个元素一左一右，左侧更大，右侧更小，则称为逆序对\n任何两个元素都可能构成逆序，所以长度为n的序列而言，逆序对的总数有可能多达O(n^2)，而将每一个逆序对都记到后面的账上，则对任何一个节点p，所对应的逆序对的总和则是整个序列逆序对的总数。\n\n p所对应的inversion有多少个，p就需要经过多少次比较抵达最终的插入位置，i（p）即是查找长度\n最好情况即是所有元素顺序输入，逐次递增，不含任何逆序对，所有，O（I+n），I为0\n相反，完全逆序输入情况，复杂度为n^2，其中任何一对都为逆序对。\n敏感输入(input-sensitive)：算法复杂度不光取决于问题的规模，而更多取决于输入本身所具有的特性，也就是无序程度。\n","categories":["数据结构"],"tags":["数据结构与算法"]},{"title":"图应用","url":"/2021/12/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE%E5%BA%94%E7%94%A8/","content":"图应用双连通分量判定准则\n\n给定无向图，如何确定BCC？\n从任一顶点出发，构造DFS树，根据DFS留下的标记，甄别是否是关节点\n\nDFS之后得到的那个叶子不会是关键点，因为删除节点后，连通量不会增加。因此，所有叶子可排除在外\n根：根在DFS中是随机的，只要不是只有1度，那必然是关节点。\n内部节点：\n根据回边是否指向比v高的祖先，指向，则v不是；若刚好指向v，则v是。\n\n\n\n\n算法#define hca(x) (fTime) //利用此处闲置的fTimetemplate&lt;typename Tv,typename Te&gt;void Graph&lt;Tv,Te&gt;::BCC(int v,int &amp; clock,stack&lt;int&gt; &amp; S)&#123;    hca(v) = dTime(v) = ++clock; status(v) = DISCOVERED;S.push(v);    for (int u = firstNbr(v);-1 &lt; u;u = nextNbr(v,u))        switch(status(u))            case UNDISCOVERED:    \t\t\tparent(u) = v; type(v,u) = TREE; //拓展树边    \t\t\tBCC(u,clock,S); //从u开始遍历，返回后...    \t\t\tif(hca(u) &lt; dTime(v)) //若u经后向边指向v的真祖先                    hca(v) = min(hca(v),hca(u)); //则v亦必如此    \t\t\telse //否则，则v为关节点(u即是一个BCC，且其中顶点此时正集中于栈S的顶部)                    while(u != S.pop());//弹出当前BCC中(除v外)的所有节点    \t\t\tbreak;            case DISCOVERED:    \t\t\ttype(v,u) = BACKWARD;    \t\t\tif(u != parent(v))                    hca(v) = min(hca(v),dTime(u));//更新hca[v],越小越高    \t\t\tbreak;    \t\tdefault: //VISITED(digraphs only)    \t\ttype(v,u) = dTime(v) &lt; dTime(u) ? FORWRD : CROSS;    \tbreak;&#125;\n\n实例\n\n\n\n优先级搜索早期向量和列表的访问次序是根据其结构本身，线性的次序，是显示可预测的。\nPFS：用某种数据结构把元素组织起来，并给各个元素分配一个优先级数，每一次做一个选择，对象就是优先级的拥有者，取出访问，循环至结束\nADT：\n\n\nDijkstra算法最短路径算法：O(1)\n\n一张网，拉离桌面，随着每一个点被拉离桌面，就能知道他们的次序，精确的记下拉离桌面的时间，则知道了最短距离\n每个点的优先级都是根据离开了桌面的前人来更新的\n拒绝负权边\n\n\nPrim算法最小支撑树\n\n\n","categories":["数据结构"],"tags":["数据结构与算法"]},{"title":"图","url":"/2021/12/07/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE/","content":"图概述邻接+关联关系G = (V;E) 顶点;边\n邻接：顶点与顶点之间的关系\n关联：顶点以及与它相关的某条边的关系\n序列和树是图的一种特例\n\n\n在图中，任何两个节点之间都允许存在邻接关系，此课不讨论自环边\n无向图/有向图总度数(D)等于边数(e)的两倍。\nD=2e\n图G的顶点数n和边数e的关系\n\n若G是无向图，则0≤e≤n(n-1)/2。\n恰有n(n-1)/2条边的无向图称无向完全图(Undireet-ed Complete Graph)。\n\n若G是有向图，则0≤e≤n(n-1)。\n恰有n(n-1)条边的有向图称为有向完全图(Directed Complete Graph)。\n\n\nu，v分别称作边(u，v)的尾(tail)，头(head)\n混合图：既有有向边，又有无向边\n\n路径+环路简单路径simple path：如果在一条通路中不含重复的节点\n环路：路径的起点终点相同，也有简单与不简单之分\n有向无环图(DAG)：一个有向图中不包含任何环路\n欧拉环路：所有的有向边都可以构成一个环路\n哈密尔顿环路：经过每一个点一次而且恰好一次    \n邻接矩阵Graph模板类\n\n邻接矩阵+关联矩阵描述顶点之间相互邻接关系的一种形式\n\n\n无向图具有冗余性\n带权图：各边记录的权重记录于对应的单元 \n顶点和边vertex\ntypedef enum &#123;UNDISCOVERED,DISCOVERED,VISITED&#125; VStatus;template&lt;typename Tv&gt;struct Vertex &#123; //顶点对象(并未严格封装)    Tv data;int inDegree,outDegree; //数据、出入度数    VStatus status; //(如上三种)状态    int dTime,fTime; //时间标签    int parent; //在遍历树中的父节点    int priorty; //在遍历树种的优先级(最短通路、极短跨边等)    Vertex(Tv const &amp; d): //构造新顶点    data(d),inDegree(0),outDegree(0),status(UNDISCOVERED),    dTime(-1),fTime(-1),parent(-1),priority(INT_MAX)&#123;&#125;&#125;;\n\nEdge\ntypedef    enum&#123;UNDETERMINED,TREE,CROSS,FORWARD,BACKWARD&#125;\tEStatus;template&lt;typename T&gt;struct Edge&#123; //边对象(并未严格封装)    T data; //数据    int weight; //权重    EStatus status; //类型    Edge(Te const &amp; d,int w)://构造新边    \tdata(d),weight(w),status(UNDETERMINED)&#123;&#125;&#125;；\n\n邻接矩阵GraphMatrix\n用邻接矩阵实现含n个顶点e条边的图，空间复杂度;O(n^2)\n删除边(i, j)的时间复杂度:O(1)\n遍历顶点v的所有邻居的时间复杂度:O(n)\n访问顶点v中存储的数据的时间复杂度:O(1)\ntemplate&lt;typename Tv,typename Te&gt;class GraphMatrix:public Graph&lt;Tv,Te&gt;&#123;private:    vector&lt;Vertex&lt;Tv&gt;&gt; V; //顶点集    Vector&lt;Vector&lt;Edge&lt;Te&gt;*&gt;&gt; E; //二维向量，边集 E[i][j]public:    /*操作接口：顶点相关，边相关，。。。*/    GraphMatrix() &#123;n = e = 0;&#125; //构造    ~GraphMatrix()&#123; //析构        for (int j = 0;j &lt; n;j++)            for(int k = 0;k &lt; n;k++)                delete E[j][k]; //清除所有动态申请的边记录    &#125;&#125;\n\n\n顶点静态操作Tv &amp; vertex(int i) &#123;return V[i].data;&#125; //数据int inDegree(int i) &#123;return V[i].inDegree;&#125; //入度int outDegree(int i) &#123;return V[i].outDegree;&#125; //出度Vstatus &amp; status(int i) &#123;return V[i].status;&#125; //状态int &amp; dTime(int i) &#123;return V[i].dTime;&#125;int &amp; fTime(int i) &#123;return V[i].fTime;&#125;int &amp; parent(int i) &#123;return V[i].parant;&#125; //在遍历树中的父亲int &amp; priority(int i) &#123;return V[i].priority;&#125; //优先级数\n\n对于任意顶点i，如何枚举其所有的邻接顶点neighbor？\ni在邻接矩阵中对应的那一行，或0或1\nint nextNbr(int i,int j)&#123; //若已枚举至邻居j，则转向下一邻居    while((-1 &lt; j) &amp;&amp; !exist(i,--j)); //逆向顺序查找，O(n)    return j;&#125;int firstNbr(int i)&#123;    return nextNbr(i,n);&#125; //首个连接，通过假想哨兵n\n\n边操作bool exists(int i,int j) &#123;//判断(i,j)是否存在    return (0 &lt;= i) &amp;&amp; (i &lt; n) &amp;&amp; (0 &lt;= j) &amp;&amp; (j &lt; n) &amp;&amp; E[i][j] != NULL; //短路求值&#125; //以下假定exists(i,j)...Te &amp; edge(int i,int j) //边(i,j)的数据&#123; return E[i][j]-&gt;data; &#125; //O(1)Estatus &amp; status(int i,int j) //边(i,j)的状态&#123; return E[i][j]-&gt;status; &#125; //O(1)Estatus &amp; Weight(int i,int j) //边(i,j)的权重&#123; return E[i][j]-&gt;Weight; &#125; //O(1)\n\n如何在一幅图中插入一条边\n假设顶点i和顶点j之间连接一条有向边，只需要将待插入的边的信息封装为一个具体的边记录，然后将新的边记录的地址存入邻接矩阵对应的那个单元，反过来这个单元也将指向记录\nvoid insert(Te const&amp; edge,int w,int i,int j)&#123; //插入(i,j,w)    if (exists(i,j)) return; //忽略已有的边    E[i][j] = new Edge&lt;Te&gt;(edge,w); //创建新边    e++; //更新边计数    v[i].outDegree++; //更新关联顶点i的出度    v[j].inDegree++; //更新关联顶点j的入度&#125;\n\n边删除\n将对应的边记录释放，然后邻接矩阵中的引用指向空\nTe remove(int i,int j)&#123; //删除顶点i和j之间的联边(exists(i,j))    Te eBak = edge(i,j); //备份边(i,j)的信息    delete E[i][j]; E[i][j] = NULL; //删除边(i,j)    e--; //更新边计数    V[i].outDegree--; //更新关联顶点i的出度    V[j].inDegree--; //更新关联顶点j的入度    return eBak; //返回被删除边的信息&#125;\n\n顶点动态操作\nint insert(Tv const &amp; vertex) &#123; //插入顶点，返回编号    for (int j = 0;j &lt; n;j++) E[j].insert(NULL); n++; //第一步：插入新一列    E.insert(vector&lt;Edge&lt;Te&gt;*&gt;(n,n,NULL)); //第二三步：长度为新n的行向量   \treturn v.insert(Vertex&lt;Tv&gt;(vertex)); //\t第四步：创建顶点记录，存入顶点向量&#125;\n\n\n综合评价优点：\n\n直观，易于理解和实现\n适用范围广\n判断两点之间是否存在联边O(1)\n获取顶点的度数：O(1)，添加、删除边后更新度数：O(1)\n扩展性：\n得益于vector良好的空间控制策略\n空间溢出等情况可“透明地”予以处理\n\n\n\n缺点：\n\nO(n^2)空间，与边数无关！\n真会有这么多条边？\n平面图：不相联的边不能相交，可嵌于平面的图\n欧拉公式出发，对于平面图而言，边的总是不可能超过顶点的总数。&lt;&lt;n^2 ,此时空间利用率约等于 1/n\n\n广度优先搜索支撑树\n以S为起点，将所有顶点划分为若干个等价类，同一等价类内部，各顶点的边不会被采纳，只有连接于相邻等价类之间的边才会被采纳(未必)\n所有被保留并且采纳的边，足以把所有的点连起来，也不至于造成环路(极大无环图)\n等价类到起点S的距离是逐次单调变化，等同于树的层次遍历\n实现Graph::BFS()\ntemplate&lt;typename Tv,typename Te&gt; //顶点类型，边类型void Graph&lt;Tv,Te&gt;::BFS(int v,int &amp; clock)&#123;    Queue&lt;int&gt; Q; status(v) = DISCOVERED; Q.enqueue(v); //初始化    while (!Q.empty())&#123;        int v = Q.dequeue();        dTime(v) = ++clock; //取出队首顶点v，并        for (int u = firstNbr(v); -1 &lt; u;u = nextNbr(v,u)) //考察v的每一邻居u            /*视u的状态，分别处理...*/            status(v) = VISITED; //至此，顶点访问完毕    &#125;&#125;\n\nwhile (!Q.empty())&#123;       int v = Q.dequeue();       dTime(v) = ++clock; //取出队首顶点v，并       for (int u = firstNbr(v); -1 &lt; u;u = nextNbr(v,u)) //考察v的每一邻居u           if (UNDISCOVERED == status(u))&#123;               status(u) = DISCOVERED; Q.enqueue(u); //发现该顶点               status(v,u) = TREE; parent(u) = v; //引入树边           &#125; else //若u已被发现（正在队列中），或者甚至已访问完毕（已出队列）               status(v,u) = CROSS; //将(v,u)归类于跨边           status(v) = VISITED; //至此，顶点访问完毕   &#125;\n\n实例\n\n\n\n当不再有新的tree edge生成，所有节点都已转成visited状态，剩下的tree edge生成一棵遍历支撑树\n多连通在含有多个连用域时，从多个起点s出发未必能够抵达其他连通域，如何使得BFS搜索足以覆盖整幅图，而不是某个连通域\ntemplate&lt;typename Tv,typename Te&gt; //顶点类型、边类型void Graph&lt;Tv,Te&gt;::bfs(int s)&#123; //s为起始顶点    reset(); int clock = 0; int v = s; //初始化O(n+e)    do //逐一检查所有顶点，一旦遇到尚未发现的顶点        if (UNDISCOVERED == status(v)) //累计O(n)            BFS(v,clock); //即从该顶点出发启动一次BFS    while (s != (v = (++v % n)));    //按序号访问，故不漏不重&#125;\n\n并非对每个顶点都启动搜索，此方法可保证对于每个连通域只有一个顶点可以作为起点引起它所属的那个连通域被完全遍历，每个连通域只启动一次BFS，搜索时间累计全图的一次遍历\n复杂度外部while循环因为每个顶点都会仅一次入队，所以dequeue操作也将执行O(n)次\n内部for(循环)是对顶点v所对应的行向量进行线性扫描n个单元\n在对整个行向量的访问过程中，所有的元素都有极高的概率处于高速缓存中\n\n连续、规则、紧凑的组织形式利于高速缓冲机制发挥作用\n存储级别之间巨大的速度差异，在实际应用中往往更为举足轻重\n\n\n最短路径树结构中，相对于树根节点，都对应于一条唯一的通路，路径的长度称为顶点v的深度，每一个等价类的深度指标都是相等的，树的层次遍历则是按照这一指标将所有顶点枚举出来\nBFS所给出的顶点序列，也是按照非降次序单调排列的。\n在最终生成的BFS树中，每个顶点与s之间的那条通路恰好就是这两个顶点之间的最短通路\n深度优先搜索深度优先搜索算法策略更为简明，过程更为复杂，功能更为强大\nDFS(s) \n​    访问顶点s\n​    若s尚有未被访问的邻居，则任取其一u，递归执行DFS(u)\n​    否则，返回\n\n框架template &lt;typename Tv,typename Te&gt; //顶点类型、边类型void Graph&lt;Tv,Te&gt;::DFS(int v,int &amp; clock)&#123;    dTime(v) = ++clock; status(v) = DISCOVERED; //发现当前顶点v    for (int u = firstNbr(v);-1 &lt; u;u = nextNbr(v,u)) //枚举v的每一邻居u        /*...视u的状态，分别处理...*/        /*...与BFS不同，含有递归...*/        status(v) = VISITED; fTime(v) = ++clock; //\t至此，当前顶点v方告访问完毕&#125;\n\n细节for (int u = firstNbr(v);-1 &lt; u;u = nextNbr(v,u)) //枚举v的每一邻居u    switch (status(u))&#123;        case UNDISCOVERED:            status(v,u) = TREE; parent(u) = v; DFS(u,clock); break; //递归        case DISCOVERED: //u已被发现但尚未访问完毕，应属被后代指向的祖先            status(v,u) = BACKWARD; break;        default: //U已放我完毕，则视承袭关系分为前向边或跨边            status(v,u) = dTime(v) &lt; dTime(u) ? FORWARD : CROSS; break;    &#125;\n\n无向图\n\n有向图\n\n一旦发现了backward边，则出现了一条回路\na的可达区都扫描完毕，第一轮循环结束\n\n粗边构成两颗遍历树\n嵌套引理顶点的活动期：active[u] = (dTime[u] , fTime[u])\n没有血缘关系的节点，活跃期彼此不搭\n\n拓扑排序零入度任给有向图G(不一定是DAG)，尝试将所有顶点排成一个线性序列，使其次序须与原图相容(每一顶点都不会通过边指向前驱顶点)\n\n提出不需要前驱的点，逐渐递归\n\n零出度\n\n","categories":["数据结构"],"tags":["数据结构与算法"]},{"title":"绪论","url":"/2021/12/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%BB%AA%E8%AE%BA/","content":"绪论计算计算是：\n\n研究对象：研究计算过程中所蕴含本质的内在规律，总结挖掘出其中的一般性的方法以及典型的技巧\n研究目的：实现高效，低耗的计算\n\n算法：即在特定计算模型下，旨在解决特定问题的指令序列\n程序！=算法\n有穷性：\n对于任何输入，经有穷次基本操作，都可以得到输出 \n好算法=正确+健壮+可读+效率（速度快，空间少）\n图灵机\n进行复位是为了在软件开发过程中相互合作的准则，即规范\nRAM模型\n一个算法好不好并不取决于CPU主频运行的快慢， 而取决于它本身需要执行多少次CPU的计算\n\n\n执行过程可以记录为一张表\n表的行数既是所执行基本指令的总条数\n能够客观度量算法的执行时间\n\n图灵机、RAM等模型为度量算法性能提供了准确的尺度\n渐进复杂度在考察DSA时应该更多看中它的长远（处理更大问题时的潜力如何），也不必过多的纠结于它的细微不足，应该更多的看到它的主要方面，主流\n大O记号从悲观的角度做分析\n\n长远，当n足够大；主流，忽略所有常系数与低次项这些非主流的因素，使得主流信息可以突出\n复杂度分析算法分析的两个主要任务=正确性（不变形x单调性）+复杂度\n复杂度分析的主要方法\n\n迭代：级数求和\n递归：递归跟踪+递归方程\n猜测+验证\n\n级数\n\n循环\n从渐进的阶次而言，二者是完全相等的，都是平方的量级\n起泡排序\n问题：该算法必然会结束？至多需迭代多少趟？\n不变形：经k轮扫描交换后，最大的k个元素必然就位\n单调性：经k轮扫描后交换后，问题规模缩减至n-k\n正确性：经至多n趟扫描后，算法必然会终止，且能给出正确的答案\n\n封底估算除了大O计算这种定性的定界方法，在很多时候需要准确的定量估算\n迭代与递归减而治之\n空间复杂度考量除了输入本身所占的空间之外，所需要的另加用于计算所必须的空间总量\n\n为求解一个大规模的问题，可以将其划分为两个子问题：其一平凡，另一规模缩减\n递归跟踪：直观形象，仅适用于简明的递归模式\n\n递推方程：间接抽象，更适用于复杂的递归模式\n\n\n分而治之为求解一个大规模的问题，可以将其划分为若干子（通常两个）问题，规模大体相当\n\n\n动态规划fib的封底估算\n\nfib递归跟踪\n\nfib迭代\n\n解决方法（记忆）：将已计算过实例的结果制表备查\n解决方法（动态规划）：颠倒计算方法，由自顶而下递归，为自底而上迭代 \n\n公共子序列\n减而治之：将相同的末字符切掉，分成一个平凡的问题和一个小于1的相同规模问题\n\n分而治之：若末尾字符不相同，则大胆切除\n\n单调性：无论如何，每经过一次对比，原问题的规模必可减小。具体地，作为输入的两个序列，至少其一的长度缩短一个单位\n最好情况（不出现第2种情况）下，只需O（n+m）时间\n但问题在于，（在第2种情况）原问题将分解为两个子问题，更糟糕的是，它们在随后进一步导出的子问题，可能雷同\n","categories":["数据结构"],"tags":["数据结构与算法"]},{"title":"栈与队列","url":"/2021/12/05/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/","content":"栈与队列last in first out\n\n栈既然属于序列的特例，故可直接基于向量或列表派生\ntemplate&lt;typename T&gt; class Stack:public vector&lt;T&gt;&#123; //由向量派生public: //size()、empty()以及其他开放接口均可直接沿用    void push(T const &amp; e)&#123; insert(size(),e);&#125; //入栈    T pop()&#123; return remove(size() - 1);&#125; //出栈    T &amp; top()&#123; return (*this)[size() - 1];&#125; //取顶&#125;; //以向量首/末端为栈底/顶——颠倒过来呢？每一次操作都会涉及到向量中的所有元素\n\n进制转换在计算过程中，没得到一个数位就通过push压入栈中\n\nvoid convert(stack&lt;char&gt; &amp; s,int64 n,int base)&#123;    static char digit[] = //新进制下的数位符号，可视base取值范围适当扩充    &#123;&#x27;0&#x27;,&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;4&#x27;,&#x27;5&#x27;,&#x27;6&#x27;,&#x27;7&#x27;,&#x27;8&#x27;,&#x27;9&#x27;,&#x27;A&#x27;,&#x27;B&#x27;,&#x27;C&#x27;,&#x27;D&#x27;,&#x27;E&#x27;,&#x27;F&#x27;&#125;;    while(n &gt; 0)    &#123; //由低到高，逐一计算出新进制下的各数位        s.push(digit[n % base]); //余数（对应的数位）入栈        n /= base; //更新为其对base的除商    &#125;&#125;\n\nmain()&#123;    stack&lt;char&gt; S;    convert(s,n,base); //用栈记录转换得到的各数位    while( !S.empty())         printf( &quot;%c&quot;,S.pop()); //逆序输出&#125;\n\n括号匹配\n\n平凡：无括号的表达式是匹配的\n\n\nbool paren(const char exp[],int lo,int hi)&#123; //exp[lo,hi)    stack&lt;char&gt; S; //使用栈记录已发现但尚未匹配的左括号    for(int i = 0;i &lt; hi;i++) //逐一检查当前字符        if(&#x27;(&#x27; == exp[i]) S.push(exp[i]);//遇左括号：则进栈    \telse if( !S.empty()) S.pop(); //遇右括号；若栈非空，则弹出左括号    \telse return false; //否则（遇有括号时栈已空），必不匹配    return S.empty(); //最终，栈空当且仅当匹配&#125;\n\n\n之所以不采用计数器方式是，无法用于多种括号并存情况，栈只需约定“括号”的通用格式，而不必事先固定括号的类型与数目\n栈混洗\n通过中转栈S，将A的元素转入B中\nS.push(A.pop())B.push(S.pop())\n\n\n\n甄别\n\n对于任何1&lt;=j&lt;k&lt;=n，[…,k…,i,…,j,…&gt; 必非栈混洗\nO（n）算法：直接借助栈A、B和S，模拟混洗过程\n​                        每次S.pop()之前，检测S是否已空；或需弹出的元素在S中，却非顶元素\n\n合法的栈混洗序列与合法的括号匹配表达式之间存在着一一对应的关系，n个元素的栈混洗有多少种，n对括号所能构成的合法表达式也就有多少种\n中缀表达式求值典型应用场合\n逆序输出：输出次序与处理过程颠倒；递归深度和输出长度不易预知\n递归嵌套：具有相似性的问题可递归描述，但分支位置和嵌套深度不固定\n延迟缓冲：线性扫描算法模式中，在预读足够长之后，方能确定可处理的前缀\n栈式计算：基于栈结构的特定计算模式\n\n在面对比较长的表达式时，很难定位当前可以计算的运算符，如果以线性扫描的次序处理表达式，计算的次序未必与扫描的次序完全一致\n可以利用栈结构，所有扫描过的部分保存为栈\n\n然而有一些栈顶的表达式并不自然，所以需要把运算符和运算数分别对待\nfloat evaluate(char* S,char* &amp; RPN)&#123;//中缀表达式求值    stack&lt;float&gt; opnd; stack&lt;char&gt; optr; //运算数栈，运算符栈    optr.push(&#x27;\\0&#x27;);    while(!optr.empty())    &#123; //逐个处理各字符，直至运算符栈空        if(isdigit(*S)) //若当前字符为操作数，则读入（可能多位的）操作数            readNumber(S,opne);        else //若当前字符为运算符，则视其与栈顶运算符之间优先级的高低            switch(orderBetween(optr.top(),*S))            &#123;/*分别处理*/&#125;    &#125;    return opnd.pop(); //弹出最后的计算结果&#125;\n\n不同优先级处理方法\nswitch(orderBetween(optr.top(),*S))&#123;    case &#x27;&lt;&#x27;: //栈顶运算符优先级更低        optr.push(*S);        S++;        break; //计算推迟，当前运算符进栈    case &#x27;=&#x27;: //优先级相等(当前运算符为右括号，或尾部哨兵&#x27;\\0&#x27;)        optr.pop();        S++;        break; //脱括号并接收下一个字符    case &#x27;&gt;&#x27;:        &#123; //栈顶运算符优先级更高，实施相应的计算，结果入栈            char op = optr.pop(); //栈顶运算符出栈，执行对应的运算            if(&#x27;!&#x27; == op) opnd.push(calc(op,opne.pop()); //一元运算符            else               &#123;                float pOpnd2 = opnd.pop(),pOpnd1 = opnd.pop(); //二元运算符                opnd.push(calcu(pOpnd1,op,pOpnd2)); //实施计算，结果入栈               &#125;                break;              &#125;        &#125;\n\n当前栈顶左括号，当前字符右括号，表明右括号之前的子表达式已都执行完毕，所以左括号弹出，字符指向下一个，末尾\\0同理\n逆波兰表达式（RPN）\n将表达式优先级转化为运算符在RPN表达式序列中出现的次序，谁先出现谁就优先计算\n手工转换\n转换后运算符的次序有可能颠倒改变，然而运算数却是不变的\n\n队列First in first out\n只能在队尾插入（查询）：enqueue（） + rear（）\n只能在队头插入（查询）：dequeue（） + front（）\n队列属于序列的特例，则可直接基于向量或列表派生\ntemplate&lt;typename T&gt; class Queue:public List&lt;T&gt;&#123;public:    void enqueue(T const &amp; e)&#123; insertAsLast(e);&#125; //尾部入队    T dequeue() &#123; return remove(first()); &#125; //首部出队    T &amp; front() &#123; return first()-&gt;data; &#125; //队首&#125;；\n\n如此实现的队列接口，均只需O(1)时间\n","categories":["数据结构"],"tags":["数据结构与算法"]},{"title":"第十章 信号量和管程","url":"/2021/11/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter10%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%92%8C%E7%AE%A1%E7%A8%8B/","content":"第十章 信号量和管程信号量信号量的抽象数据类型\n\n一个整形(sem),具有两个原子操作\nP(): sem减一,如果sem&lt;0,等待,否则继续\nV(): sem加一,如果sem≤0,唤醒一个等待的P\n\n信号量是整形\n信号量是被保护的变量\n\n初始化完成后,唯一改变一个信号量的值的办法是通过P()和V()\n操作必须是原子\n\nP()能够阻塞,V()不会阻塞\n我们假定信号量是公平的\n\n没有线程被阻塞在P()仍然堵塞如果V()被无限频繁调用(在同一个信号量)\n在实践中,FIFO经常被使用\n\n两个类型信号量\n\n二进制信号量: 可以是0或1\n计数信号量: 可以取任何非负数\n两者相互表现(给定一个可以实现另一个)\n\n信号量可以用在2个方面\n\n互斥\n条件同步(调度约束——一个线程等待另一个线程的事情发生)\n\n10.3 信号量的使用\n用二进制信号量实现的互斥\nmutex = new Semaphore(1);mutex-&gt;P();...mutex-&gt;V();\n用二进制信号量实现的调度约束\ncondition = new Semaphore(0);//Thread A...condition-&gt;P(); //等待线程B某一些指令完成之后再继续运行,在此阻塞...//Thread B...condition-&gt;V(); //信号量增加唤醒线程A...\n\n\n一个线程等待另一个线程处理事情\n比如生产东西或消费东西(生产者消费者模式)\n互斥(锁机制)是不够的\n有界缓冲区的生产者-消费者问题\n一个或者多个生产者产生数据将数据放在一个缓冲区里\n单个消费者每次从缓冲区取出数据\n在任何一个时间只有一个生产者或消费者可以访问该缓冲区\n\n\n\n正确性要求\n\n在任何一个时间只能有一个线程操作缓冲区(互斥)\n当缓冲区为空时,消费者必须等待生产者(调度,同步约束)\n当缓存区满,生产者必须等待消费者(调度,同步约束)\n\n每个约束用一个单独的信号量\n\n二进制信号量互斥\n一般信号量 fullBuffers\n一般信号了 emptyBuffers\n\nclass BoundedBuffer&#123;\t\tmutex = new Semaphore(1);\t\tfullBuffers = new Semaphore(0);   //说明缓冲区初始为空 \t\temptyBuffers = new Semaphore(n);  //同时可以有n个生产者来生产&#125;;BoundedBuffer::Deposit(c)&#123;\t\temptyBuffers-&gt;P();\t\tmutex-&gt;P();\t\tAdd c to the buffer;\t\tmutex-&gt;V();\t\tfullBuffers-&gt;V();&#125;BoundedBuffer::Remove(c)&#123;\t\tfullBuffers-&gt;P();\t\tmutex-&gt;P();\t\tRemove c from buffer;\t\tmutex-&gt;V();\t\temptyBuffers-&gt;V();&#125;\n\n10.4 信号量的实现使用硬件原语\n\n禁用中断\n原子指令\n\n类似锁\n\n禁用中断\n\nclass Semaphore&#123;\t\tint sem;\t\tWaitQueue q;&#125;;Semaphore::P()&#123;\t\t--sem;\t\tif(sem &lt; 0)&#123;\t\t\t\tAdd this thread t to q;\t\t\t\tblock(p);\t\t&#125;&#125;;Semaphore::V()&#123;\t\t++sem;\t\tif(sem &lt;= 0)&#123;\t\t\t\tRemove a thread t from q;\t\t\t\twakeup(t);\t\t&#125;&#125;\n\n信号量的双用途\n\n互斥和条件同步\n但等待条件是独立的互斥\n\n读,开发代码比较困难\n\n程序员必须非常精通信号量\n\n容易出错\n\n使用的信号量已经被另一个线程占用\n忘记释放信号量\n\n不能够处理死锁问题\n10.5 管程管程是包含了一系列的共享变量，以及针对共享变量的操作函数的组合模块\n目的：分离互斥和条件同步的关注\n什么是管程\n\n一个锁：指定临界区\n0或者多个条件变量：等待/通知信号用于管理并发访问共享数据\n\n一般方法\n\n收集在对象/模块中的相关共享数据\n定义方法来访问共享数据\n\nLock\n\nLock::Acquire() 等待直到锁可用,然后抢占锁\nLock::Release() 释放锁,唤醒等待者如果有\n\nCondition Variable\n\n允许等待状态进入临界区\n允许处于等待(睡眠)的线程进入临界区\n某个时刻原子释放锁进入睡眠\n\n\nWait() operation\n释放锁,睡眠,重新获得锁放回\n\n\nSignal() operation(or broadcast() operation)\n唤醒等待者(或者所有等待者),如果有\n\n\n\n实现\n\n需要维持每个条件队列\n\n线程等待的条件等待signal（）\nclass Condition&#123;\t\tint numWaiting = 0;\t\tWaitQueue q;&#125;;Condition::Wait(lock)&#123;\t\tnumWaiting++;\t\tAdd this thread t to q;\t\trelease(lock);\t\tschedule(); //need mutex\t\trequire(lock);&#125;Condition::Signal()&#123;\t\tif(numWaiting &gt; 0)&#123;\t\t\t\tRemove a thread t from q;\t\t\t\twakeup(t); //need mutex\t\t\t\tnumWaiting--;\t\t&#125;&#125;\n管程解决生产者-消费者问题\nclass BoundedBuffer&#123;\t\tLock lock;\t\tint count = 0;  //buffer 为空\t\tCondition notFull,notEmpty;&#125;;BoundedBuffer::Deposit(c)&#123;\t\tlock-&gt;Acquire();    //管程的定义:只有一个线程能够进入管程\t\twhile(count == n)\t\t\tnotFull.Wait(&amp;lock); //释放前面的锁\t\tAdd c to the buffer;\t\tcount++;\t\tnotEmpty.Signal();\t\tlock-&gt;Release();&#125;BoundedBuffer::Remove(c)&#123;\t\tlock-&gt;Acquire();\t\twhile(count == 0)\t\t\tnotEmpty.Wait(&amp;lock);\t\tRemove c from buffer;\t\tcount--;\t\tnotFull.Signal();\t\tlock-&gt;Release();&#125;\n\n由于同步互斥机制的存在，即使有方法解决，但由于不确定性\n\n开发/调试并行程序很难\n\n非确定性的交叉指令\n\n\n同步结构\n\n锁：互斥\n条件变量：有条件的同步\n其他原语：信号量\n\n\n怎样有效的使用这些结构\n\n制定并遵循严格的程序设计风格/策略\n\n\n\n10.6-10.8 经典同步问题读者-写者问题动机\n\n共享数据访问\n\n两种类型使用者\n\n读者：不需要修改数据\n写者：读取和修改数据\n\n问题的约束\n\n允许同一时间有多个读者，但在任何时候只有一个写者\n当没有写者时，读者才能访问数据\n当没有读者和写者时，写者才能访问数据\n在任何时候只能有一个线程可以操作共享变量\n\n多个并发进程的数据集共享\n\n读者 - 只读数据集：他们不执行任何更新\n写者 - 可以读取和写入\n\n共享数据\n\n数据集\n信号量CountMutex初始化为1\n信号量WriteMutex初始化为1\n整数Rcount（读者的个数）初始化为0\n\n\n读者优先\n\n只要有一个读者处于活动状态, 后来的读者都会被接纳.如果读者源源不断的出现,那么写者使用处于阻塞状态\n//信号量实现//writersem_wait(WriteMutex);write;sem_post(WriteMutex);//readersem_wait(CountMutex);if(Rcount == 0)\t\tsem_wait(WriteMutex); //确保后续不会有写者进入++Rcount;read;--Rcount;if(Rcount == 0)\t\tsem_post(WriteMutex); //全部读者全部离开才能唤醒写者sem_post(CountMutex);\n\n\n写者优先\n\n一旦写者就绪,那么写者会尽可能的执行写操作.如果写者源源不断的出现的话,那么读者就始终处于阻塞状态\n//writerDatabase::Write()&#123;\t\tWait until readers/writers;\t\twrite database;\t\tcheck out - wake up waiting readers/writers;&#125;//readerDatabase::Read()&#123;\t\tWait until no writers;\t\tread database;\t\tcheck out - wake up waiting writers;&#125;//管程实现AR = 0; // # of active readersAW = 0; // # of active writersWR = 0; // # of waiting readersWW = 0; // # of waiting writersCondition okToRead;Condition okToWrite;Lock lock;//writerPublic Database::Write()&#123;\t\t//Wait until no readers/writers;\t\tStartWrite();\t\twrite database;\t\t//check out - wake up waiting readers/writers;\t\tDoneWrite();&#125;Private Database::StartWrite()&#123;\t\tlock.Acquire();\t\twhile((AW + AR) &gt; 0)&#123;\t\t\t\tWW++;\t\t\t\tokToWrite.wait(&amp;lock);\t\t\t\tWW--;\t\t\t\t&#125;\t\tAW++;\t\tlock.Release();&#125;Private Database::DoneWrite()&#123;\t\tlock.Acquire();\t\tAW--;\t\tif(WW &gt; 0)&#123;\t\t\t\tokToWrite.signal();\t\t&#125;\t\telse if(WR &gt; 0)&#123;\t\t\t\tokToRead.broadcast(); //唤醒所有reader \t\t&#125;\t\tlock.Release();&#125;//readerPublic Database::Read()&#123;\t\t//Wait until no writers;\t\tStartRead();\t\tread database;\t\t//check out - wake up waiting writers;\t\tDoneRead();&#125;Private Database::StartRead()&#123;\t\tlock.Acquire();\t\twhile(AW + WW &gt; 0)&#123;    //关注等待的writer,体现出写者优先\t\t\t\tWR++;\t\t\t\tokToRead.wait(&amp;lock);\t\t\t\tWR--;\t\t&#125;\t\tAR++;\t\tlock.Release();&#125;private Database::DoneRead()&#123;\t\tlock.Acquire();\t\tAR--;\t\tif(AR == 0 &amp;&amp; WW &gt; 0)&#123;  //只有读者全部没有了,才需要唤醒\t\t\t\tokToWrite.signal();\t\t&#125;\t\tlock.Release();&#125;\n\n10.9-10.11 哲学家就餐问题怎么来编写程序？\n\n必须有数据结构，来描述每个哲学家的当前状态；\n该状态是一个临界资源，各个哲学家对它的访问应该互斥地进行——进程互斥；\n一个哲学家吃饱后，可能要唤醒它的左邻右舍，两者之间存在着同步关系——进程同步；\n\n共享数据:Bowl of rice(data set)Semaphone fork [5] initialized to 1    #define N 5#define LEFT (i + N - 1) % N // 左邻居#define RIGHT (i + 1) % N    // 右邻居#define THINKING 0#define HUNGRY   1#define EATING   2typedef int semaphore;int state[N];                // 跟踪每个哲学家的状态semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥semaphore s[N];              // 每个哲学家一个信号量void philosopher(int i) &#123;    while(TRUE) &#123;        think(i);        take_two(i);        eat(i);        put_two(i);    &#125;&#125;void take_two(int i) &#123;    down(&amp;mutex);    state[i] = HUNGRY;    check(i);    up(&amp;mutex);    down(&amp;s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去&#125;void put_two(i) &#123;    down(&amp;mutex);    state[i] = THINKING;    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了    check(RIGHT);    up(&amp;mutex);&#125;void eat(int i) &#123;    down(&amp;mutex);    state[i] = EATING;    up(&amp;mutex);&#125;// 检查两个邻居是否都没有用餐，如果是的话，就 up(&amp;s[i])，使得 down(&amp;s[i]) 能够得到通知并继续执行void check(i) &#123;             if(state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] !=EATING) &#123;        state[i] = EATING;        up(&amp;s[i]);    &#125;&#125;\n\n","categories":["操作系统"],"tags":["信号量","管程"]},{"title":"第十一章 死锁","url":"/2021/11/24/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter11%E6%AD%BB%E9%94%81/","content":"第十一章 死锁一组阻塞的进程持有一种资源等待获取另一个进程所占有的一个资源\n由于进程的并发执行的情况导致出现死锁\n通常操作系统一般遇到死锁都使用鸵鸟算法（不理会）\n11.2 系统模型需求方：进程        需求资源：CPU，内存单元，I/O。。。\n进程对资源的访问情况：\n\n需要资源——向空闲资源申请\n得到资源——资源变为被使用状态，其他进程则不能用\n使用资源时间有限——用完释放（free）\n\n可重复使用的资源\n\n在一个时间只能一个进程使用且不能被删除\n进程获得资源，后来释放由其他进程重用\n处理器，I/O通道，主和副存储器，设备和数据结构，如文件，数据库和信号量\n如果每个进程拥有一个资源并请求其他资源，死锁可能发生\n\n使用资源\n\n创建和销毁\n在I/O缓冲区的中断，信号，消息，信息\n如果接受消息阻塞可能会发生死锁\n可能少见的组合事件会引起死锁\n\n资源分配图\n一组顶点V和边E的集合\n\nV有两种类型：\n\nP={P1,P2,…,Pn},集合包括系统中的所有进程\nR={R1,R2,…,Rm},集合包括系统中的所有资源类型\n\n\nrequesting,claiming edge - directed edge Pi → Rj\n\nassignment,holding edge - directed edge Rj → Pi\n\n\n基本情况\n\n如果如钟不包含循环==没有死锁\n如果图中包含循环\n如果每个资源类只有一个实例，那么死锁\n如果每个资源类有几个实例，可能死锁\n\n\n\n11.3 死锁特征死锁出现一定会出现以下四个条件，但是出现以下四个条件不一定死锁：（必要条件）\n\n互斥：在一个时间只能有一个进程使用资源\n持有并等待：进程保持至少一个资源正在等待获取其他进程持有的额外资源\n无抢占：一个资源只能被进程自愿释放，进程已经完成了它的任务之后\n 循坏等待：进程资源链接的关系形成了一个环\n\n\n11.4 死锁处理办法\n确保系统永远不会进入死锁状态\n\n运行系统进入死锁状态，然后恢复\n\n忽略这个问题，假装系统中从来没有发生死锁；用于大多数操作系统，包括UNIX\n\n\n11.5 死锁预防和死锁避免死锁预防限制申请方式\n\n互斥 - 共享资源不是必须的，必须占用非共享资源\n\n占用并等待 - 必须保证当一个进程请求的资源，它不持有任何其他资源（要么拿所有资源，要么sleep）\n\n需要进程请求并分配其所有资源，它开始执行之前或允许进程请求资源仅当进程没有资源\n资源利用率低：可能发生饥饿\n\n\n无抢占\n\n如果进程占有某些资源，并请求其他不能被立即分配的资源，则释放当前正占有的资源\n被抢占资源添加到资源列表中\n只有当它能够获得旧的资源以及它请求新的资源，进程可以得到执行\n\n\n循环等待 - 对所有资源类型进行排序，并要求每个进程按照资源的顺序进行申请\n\n确保进程之间形不成环\n通用操作系统用的不多，嵌入式操作系统用的多\n\n\n\n死锁避免需要操作系统具有一些额外的先验信息提供\n\n最简单和最有效的模式是要求每个进程声明它可能需要的每个类型资源的最大数目\n\n资源的分配状态是通过限定提供与分配的资源数量,和进程的最大需求（不超过最大）\n\n死锁避免算法动态检查的资源分配状态,以确保永远不会有一个环形等待状态（不安全状态，处于环形并不一定是死锁，约束较大）\n\n当一个进程请求可用资源，系统必须判断立即分配是否能使系统处于安全状态\n\n系统处于安全状态指：针对所有进程，存在安全序列序列&lt;P1,P2,…,Pn&gt;是安全的: 针对每个Pi,Pi要求的资源能够由当前可用的资源+所有的Pj持有的资源来满足,其中j&lt;i\n\n如果Pi资源的需求不是立即可用，那么Pi可以等到所有Pj完成\n当Pi完成后，Pi+1可以得到所需要的的资源，执行，返回所分配的资源，并终止\n用同样的方法，Pi+2，Pi+3和Pn能够获得其所需的资源\n\n\n如果系统处于安全状态==无死锁\n\n如果系统处于不安全状态==可能死锁\n\n避免死锁：确保操作系统永远不会进入不安全状态\n\n\n11.6 银行家算法Banker‘s Algorithm 前提条件\n\n多个资源实例\n\n每个进程都必须能最大限度地利用资源\n\n当一个进程请求一个资源，就不得不等待\n\n当一个进程获得所有的资源就必须在一段有限的时间释放它们\n\n\n银行家算法数据结构\nn = 进程数量，m = 资源类型数量\n\nmax（总需求量）：n*m矩阵。如果max[i , j] = k，表示进程Pi最多请求资源类型Rj的k个实例\n\nAvailable（剩余空闲量）：长度为m的向量。如果Available[j] = k，有k个类型Rj的资源实例可用\n\nAllocation（已分配量）：n*m矩阵。如果Allocation[i , j] = k，则Pi当前分配了k个Rj的实例\n\nNeed（未来需要量）：n*m矩阵。如果Need[i , j] = k，则Pi可能需要至少k个Rj实例完成任务\n\n\nNeed[i , j] = max[i , j] - Allocation[i , j] \n  具体算法：\n\nwork和finish分别是长度m和n的向量\n初始化： work = Available         //当前资源剩余空闲量\n​                finish[i] = false for i - 1,2，。。。，n     //线程i没结束\n\n找这样的i：        //接下来找出need比work小的进程i\n\nfinish[i] = false\n\nneedi&lt;=work\n没有找到这样的i，转到4。\n\n\n\nwork = work + Allocation      //进程i的资源需求量小于剩余空闲资源量，所以配置给它再回收\nfinish[i] = true\n转到2.\n\nif finish[i] == true for all i,           //所有进程的finish为true，表明系统处于安全状态\n\n\n\n11.7 死锁检测和死锁恢复死锁检测\n允许系统进入死锁状态\n死锁检测算法\n恢复机制\n\n\n开销大，更多用在调试系统与应用程序\n检测算法使用\n\n何时，使用什么样的频率来检测依赖于：\n\n死锁多久可能会发生？\n多久进程需要被回滚？\n\n\n如果检测算法多次被调用，有可能是资源图有多个循环，所以我们无法分辨出多个可能死锁进程中的哪些”造成”死锁\n\n\n死锁恢复\n终止所有的死锁进程\n在一个时间内终止一个进程直到死锁消除\n终止进程的顺序应该是\n进程的优先级\n进程运行了多久以及需要多少时间才能完成\n进程占用的资源\n进程完成需要的资源\n多少进程需要被终止\n进程是交互还是批处理\n\n\n\n存在强制性和不合理性\n死锁恢复是出现死锁的最后手段\n资源抢占：\n\n选择一个受害者 - 最小的成本\n回滚 - 返回一些安全状态，重启进程到安全状态\n饥饿 - 同一进程可能一直被选做受害者，包括回滚的数量\n\n11.8 IPC（进程间通讯）进程之间相互保存独立，一个进程不能访问另一个进程的地址空间\n进程与进程之间也需要一定的沟通和协作来完成大的任务\n概述\n进程通信的机制及同步\n\n不使用共享变量的进程通信\n\nIPC facility 提供2个操作：\n\nsend（message）- 消息大小固定或者可变\nreceive（message）\n\n\n如果P和Q想通讯，需要：\n\n在它们之间建立通信链路\n通过send/receive交换信息\n\n\n通信链路的实现\n\n物理（例如，共享内存，硬件总线）\n逻辑（例如，逻辑属性）\n\n\n\n​    直接通讯\n\n进程必须正确的命名对方：\n\nsend（P, message）- 发送消息到进程P\nreceive（Q, message）- 从进程Q接收信息\n\n\n通信链路的属性\n\n自动建立链路\n一条链路恰好对应一对通信进程\n每对进程之间只有一个链路存在\n链路可以是单向的,但通常是双向的\n\n\n\n间接通讯\n\n定向从消息队列接受消息\n\n每个消息队列都有一个唯一的ID\n只有它们共享了一个消息队列，进程才能够通信\n\n\n通信链路的属性\n\n只有进程共享一个共同的消息队列,才建立链路\n链接可以与许多进程相关联\n每对进程可以共享多个通信链路\n链接可以是单向或者双向\n\n\n操作\n\n创建一个新的消息队列\n通过消息队列发送和接收消息\n销毁消息队列\n\n\n原语的定义如下:\n\nsend(A, message)\nreceive(A, message)\n\n\n队列的消息被附加到链路：\n\n0容量 - 0 message\n发送方必须等待接收方\n\n有限容量 - n message的有限长度\n发送方必须等待，如果队列满\n\n无线容量 - 无限长度\n发送发不需要等待\n\n\n\n\n信号signal（信号）\n\n软件中断通知事件处理\n\n接收到信号时会发生什么\n\ncatch：指定信号处理函数被调用\nignore：依靠操作系统的默认操作\nmask：闭塞信号因此不会传送\n可能是暂时的（当处理同样类型的信号）\n\n\n\n不足\n\n不能传输要交换的任何数据\n\n管道子进程从父进程继承文件描述符\n进程不知道（或不关心）从键盘，文件，程序读取或写入到终端，文件，程序。\n例如: $ ls | more (两个进程, 管道是缓存,对于ls来说是stdout,对于more来说是stdin )\n消息队列消息队列按FIFO来管理消息\n\nmessage: 作为一个字节序列存储\nmessage queues: 消息数组\nFIFO &amp; FILO configuration\n\n共享队列进程\n\n每个进程都有私有地址空间\n在每个地址空间内，明确地设置了共享内存段\n\n优点\n\n快速，方便地共享数据\n\n不足\n\n必须同步数据访问\n\n","categories":["操作系统"],"tags":["死锁"]},{"title":"第十二章 文件系统","url":"/2021/11/26/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/chapter12%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","content":"第十二章 文件系统12.1-12.9 基本概念文件系统和文件文件系统：一种用于持久性存储的系统抽象\n\n在存储器上：组织，控制，导航，访问和检索数据\n大多数计算机系统包含文件系统\n个人电脑，服务器，笔记本电脑\nipod，tivo/机顶盒，手机/掌上电脑\ngoogle可能是由一个文件系统构成的\n\n文件：文件系统中一个单元的相关数据在操作系统中的抽象\n文件系统的功能分配文件磁盘空间\n\n管理文件块（哪一种属于哪一个文件）\n\n管理空闲空间（哪一块是空闲的）\n\n分配算法（策略）\n\n\n管理文件集合\n\n定位文件及其内容\n命名：通过名字找到文件的接口\n最常见：分层文件系统\n文件系统类型（组织文件的不同方式）\n\n提供便利及特征\n\n保护：分层来保护数据安全\n可靠性/持久性：保持文件的持久及时发生崩溃、媒体错误、攻击等\n\n文件和块文件属性\n\n名称、类型、位置、大小、保护、创建者、创建时间、最近修改时间、。。。\n\n文件头\n\n在存储元数据中保存了每个文件的信息\n保存文件的属性\n跟踪哪一块存储块属于逻辑上文件结构的哪个偏移\n\n文件描述符文件使用模式\n\n使用程序必须在使用前先“打开”文件\n\n内核跟踪每个进程打开的文件\n\n操作系统为每个进程维护一个打开文件表\n一个打开文件描述符是这个表中的索引\n\n需要元数据来管理打开文件：\n\n文件指针：指向最近的一次读写位置，每个打开了这个文件的进程都这个指针\n文件打开次数：记录文件打开的次数 - 当最后一个进程关闭了文件时，允许将其从打开文件表中移除\n文件磁盘位置：缓存数据访问信息\n访问权限：每个程序访问模式信息\n\n用户视图：\n\n持久的数据结构\n\n系统访问接口：\n\n字节的集合\n系统不会关心你想存储在磁盘上的任何数据结构\n\n操作系统内部视角\n\n块的集合（块是逻辑转换单元，而扇区是物理转换单元）\n块大小&lt;&gt;扇区大小；在UNIX中，块的大小是4KB\n\n当用户说：给我2-12字节空间时会发生什么\n\n获取字节所在的块\n返回块内对应部分\n\n如果说要写2-12字节呢？\n\n获取块\n修改块内对应部分\n写回块\n\n在文件系统中的所有操作都是在整个块空间上进行的\n\ngetc() putc() 即使每次只访问1字节的数据,也会缓存目标数据4096字节(一个磁盘块)\n\n用户怎么访问文件\n\n在系统层面需要知道用户的访问模式\n\n顺序访问：按字节一次读取\n\n几乎所有的访问都是这种方式\n\n随机访问：从中间读写\n\n不常用，但是任然重要。例如，虚拟内存支持文件：内存页存储在文件中\n更加快速 - 不希望获取文件中间的内容的时候也必须先获取块内所有的字节\n\n基于内容访问：通过特征\n\n许多系统不提供此种访问方式，相反，数据库是建立在索引内容的磁盘访问上（需要高效的随机访问）\n\n文件内部结构无结构\n\n单词，比特的队列\n\n简单记录结构\n\n列\n固定长度\n可变长度\n\n复杂结构\n\n格式化的文档\n可执行文件（如，MS word ，pdf）\n…\n\n多用户系统中的文件共享是很必要的\n访问控制\n\n谁能够获得哪些文件的哪些访问权限\n访问模式：读，写，执行，删除，列举等\n\n文件访问控制列表（ACL）\n\n文件实体，权限\n\nUNIX：\n\n&lt;用户|组|所有人,读|写|可执行&gt;\n用户ID识别用户,表明每个用户所允许的权限及保护模式\n组ID允许用户组成组,并指定了组访问权限\n\n指定多用户/客户如何同时访问共享文件\n\n和过程同步算法类似\n因磁盘I/O和网络延迟而设计简单\n\nUNIX文件系统（UFS）语义\n\n对打开文件的写入内容立即对其他打开同一文件的其他用户可见\n共享文件指针允许多用户同时读取和写入文件\n\n会话语义\n\n写入内容只有当文件关闭时可见\n\n锁\n\n一些操作系统和文件系统提供该功能\n\n目录文件以目录的方式组织起来\n目录是一类特殊的文件\n\n每个目录都包含了一张表\n\n目录和文件的树型结构，层次命名空间\n目录操作\n典型操作\n\n搜索，创建，删除文件，枚举目录，重命名文件，在文件系统中遍历一个路径\n\n操作系统应该只允许内核模式修改目录\n\n确保映射的完整性\n应用程序能够读目录（如ls）\n\n文件名的线性列表，包涵了指向数据块的指针\n\n编程简单，执行耗时\n\nHash表 - hash数据结构的线性表\n\n减少目录搜索时间\n碰撞 - 两个文件名的hash值相同\n固定大小\n\n路径遍历\n名字解析：逻辑名字转换成物理资源（如文件）的过程\n\n在文件系统中：到实际文件的文件名（路径）\n遍历文件目录直到找到目标文件\n\n举例：解析“/bin/ls”\n\n读取root的文件头（在磁盘固定位置）\n读取root的数据块；搜索“bin”项\n读取bin的文件头\n读取bin的数据块：搜索ls项\n读取ls的文件头\n\n当前工作目录\n\n每个进程都会指向一个文件目录用于解析文件名\n允许用户指定相对路径来代替绝对路径\n\n一个文件系统需要先挂载才能被访问\n一个未挂载的文件系统被挂载在挂载点上\n文件别名两个或多个文件名关联同一个文件\n硬链接：多个文件项指向一个文件\n软链接：以“快捷方式”指向其他文件（存的是路径名）\n通过存储真实文件的逻辑名称来实现\n因为目录是树型结构，引入链接可能导致出现循环路径，如何保证没有循环呢？\n\n只允许到文件的链接，不允许在子目录的链接\n每增加一个新的链接都利用循环检测算法确定是否合理\n限制路径可遍历文件目录的数量\n\n文件系统种类磁盘文件系统\n\n文件存储在数据存储设备上，如磁盘\n例如：FAT，NTFS，ext2/3，ISO9660，等\n\n数据库文件系统\n\n文件根据其特征是可被寻址的（辨识）的\n例如：WinFS\n\n日志文件系统\n\n计算机可能掉电导致文件系统混乱，因此下一次开机时会进行检查文件的内容一致性，导致开销很大，为此增加日志功能，可快速恢复\n记录文件系统的修改/事件\n例如：journaling file system\n\n网络/分布式文件系统\n\n例如：NFS，SMB，AFS，GFS\n在局域网范围内可快速方便的访问另一台机器的文件\n\n12.10 虚拟文件系统分层结构\n\n上层：虚拟（逻辑）文件系统\n底层：特定文件系统模块\n\n\n目的：对所有不同文件系统的抽象\n功能：\n\n提供相同的文件和文件系统接口\n管理所有文件和文件系统关联的数据结构\n高效查询例程，遍历文件系统\n与特定文件系统模块的交互\n\n文件系统基本数据结构：\n\n卷控制块（UNIX：“superblock”）\n\n\n每个文件系统一个\n文件系统详细的信息\n块、块的大小、空余块。计数/指针等\n\n\n文件控制块（UNIX：“vnode” or “inode”）\n\n\n每个文件一个\n文件详细信息\n许可、拥有者、大小、数据库位置等\n\n\n目录节点（Linux：“dentry”）\n\n\n每个目录项一个（目录和文件）\n将目录项数据结构及树型布局编码成树型结构\n指向文件控制块，父节点，项目列表等\n\n持续存储在二级存储中\n\n映射到磁盘的一个或多个扇区\n\n分配在存储设备中的数据块中\n\n\n当需要时加载进内存\n\n1 当文件系统挂载时进入内存\n2 当文件被访问时进入每次\n3 在遍历一个文件路径时进入内存\n\n12.11 数据缓存数据块按需读入内存\n\n提供read（）操作\n预读：预选读取后面的数据块\n\n数据块使用后被缓存\n\n假设数据将会再次被使用\n写操作可能被缓存和延迟写入\n\n两种数据块缓存方式\n\n普通缓冲区缓存\n页缓存：统一缓存数据块和内存页\n\n缓存和页式管理结合，实现基于分页的缓存机制\n分页要求\n\n当需要一个页时才将其载入内存\n\n支持存储\n\n一个页（在虚拟地址空间中）可以被映射到一个本地文件中（在二级存储中）\n\n文件数据块的页缓存\n\n在虚拟内存中文件数据块被映射成页\n文件的读/写操作被转换成对内存的访问\n可能导致缺页或设置为脏页\n\n12.12 打开文件的数据结构硬盘存的关于文件的文件控制块的内容读到内存中，把相关信息放在打开文件表里，项的索引返回给应用程序\n  打开文件描述\n\n每个被打开的文件一个\n文件状态信息\n目录项，当前文件指针，文件操作设置等\n\n打开文件表\n\n一个进程一个\n一个系统级的\n每个卷控制块也会保存一个列表\n所以如果有文件被打开将不能卸载 \n\n锁\n\n一些操作系统和文件系统提供该功能\n调节对文件的访问\n强制和劝告\n强制 - 根据锁保持情况和需求拒绝访问\n劝告 - 进程可以查看锁的状态来决定怎么做\n\n\n\n12.13 文件分配大多数文件都很小\n\n需要对小文件提供强力的支持\n块空间不能太大\n\n一些文件非常大\n\n必须支持大文件（64-bit 文件偏移）\n大文件访问需要相当高效\n\n如何为一个文件分配数据块\n分配方式\n\n连续，链式，索引\n\n指标：\n\n高效：如存储利用（外部碎片）\n表现：如访问速度\n\n连续分配文件头指定起始块和长度，数组方式\n位置/分配策略\n\n最先匹配，最佳匹配。。。\n\n优势\n\n文件读取表现好\n高效的顺序和随机访问\n\n劣势\n\n碎片\n文件增长问题\n\n组织好，性能糟糕，适合只读\n链式分配文件以数据块链表方式存储\n文件头包含了到第一块和最后一块的指针\n优点\n\n创建，增大，缩小很容易\n没有碎片\n\n缺点\n\n不可能进行真正的随机访问（访问第二块要先找到第一块）\n可靠性（一旦断了一个链。。。）\n\n索引分配为每个文件创建一个名索引数据块的非数据数据块\n\n到文件数据块的指针列表\n\n文件头包含了索引数据块\n\n得到索引快后调入内存，然后查找对应文件位置\n\n优点\n\n创建，增大，缩小很容易\n没有碎片\n支持直接访问\n\n缺点\n\n当文件很小时，存储索引的开销大\n很大的文件，索引块能够表示的数据块的个数有限，一个索引块不够，其他索引块又要如何管理\n\n链式索引块（IB+IB+…)\n线性扩展的方式，对大文件的扩展还是有限，万一链断了怎么办\n多级索引块（IB*IB…)\n分层方式灵活支持大小文件\n12.14 空闲空间列表跟踪在存储中的所有未分配的数据块\n空闲空间列表存储在哪里？\n空闲空间列表的最佳数据结构怎么样？\n用位图代表空闲数据块列表\n\n11111101101110111 如果 i = 0表明数据块i是空闲的,反之是分配的\n\n使用简单但是可能回事一个big vector\n\n160GB disk → 40M blocks → 5MB worth of bits\n\n然而，如果空闲空间在磁盘中均匀分布,那么再找到”0“之前需要扫描的开销：\n磁盘上数据块总数 / 空闲块的数目\n\n\n12.15 多磁盘管理-RAID通常磁盘通过分区来最大限度减少寻道时间\n\n一个分区是一个柱面的集合\n每个分区都是逻辑上独立的磁盘\n\n分区：硬件磁盘的一种适合操作系统指定格式的划分\n卷（多个disk变成一个卷）：一个拥有一个文件系统实例的可访问的存储空间\nRAID\n提高磁盘访问效率\n使用多个并行磁盘来增加\n\n吞吐量（通过并行）\n可靠性和可用性（通过冗余）\n\nRAID - 冗余磁盘阵列\n\n各种磁盘管理技术\nRAID level：不同RAID分类（如，RAID-0，RAID-1，RAID-5）\n\n实现\n\n在操作系统内核：存储/卷管理\nRAID硬件控制器（I/O）\n\nRAID-0（提高吞吐量）\n数据块分成多个子块，存储在独立的磁盘中\n\n和内存交叉相似\n\n通过更大的有效快大小来提供更大的磁盘带宽\nRAID-1（提高可靠性）\n可靠性成倍增长\n读取性能线性增加\n\n向两个硬盘写入，随机一个读取\n\nRAID-4（即提高性能，又增加可靠性）\n数据块级磁带配有专用奇偶校验磁盘\n\n允许从任意一个故障磁盘中恢复\n\n额外的盘完成容错功能\n往任何一个disk里写一个数据，就要往parity disk里面也做写操作\nPAID-5\n把奇偶校验的块均匀分布在不同的disk里面，开销均匀，访问并行。允许有一个disk错误\nRAID-6\n两个冗余块，有一种特殊的编码方式，允许两个磁盘错误\n12.16 磁盘调度读取或写入时，磁头必须被定为在期望的磁道，并从所期望的扇区开始\n寻到时间\n\n定位到期望的磁道所花费的时间\n\n旋转延迟\n\n从扇区的开始到到达目的处所花费的时间\n\n寻道时间是性能上区别的原因\n对单个磁盘，会有一个IO请求数目\n如果请求是随机的,那么会表现很差\nFIFO\n\n按顺序处理请求\n公平对待所有进程\n在有很多进程的情况下，接近随机调度的性能\n\n最短服务优先\n\n选择从磁臂当前位置需要移动最少的I/O请求\n总是选择最短寻道时间\n如果请求频繁出现在当前访问位置，而远处的访问请求持续得不到服务，导致饥饿现象\n访问不公平性和不均匀性\n\nskan\n\n磁臂在一个方向上移动，满足所有未完成的请求，直到磁臂到达该方向上最后的磁道\n\n调度方向\n\n\nc-skan\n\n限制了仅在一个方向上扫描\n当最后一个磁道也被访问过了后，磁臂返回到磁盘的另外一端再次进行扫描\n公平效率高\n\nc-loop\n\n磁臂先到达该方向上最后一个请求处，然后立即反转\n\n","categories":["操作系统"],"tags":["文件系统"]},{"title":"两数之和","url":"/2022/02/11/LeetCode/%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/","content":"暴力法class Solution &#123;    public:        vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123;        vector&lt;int&gt; s;        for( int i = 0;i &lt; nums.size()-1;i++ )            for( int j = i + 1;j &lt; nums.size();j++ )                if( target == nums[i] + nums[j])&#123;                    s.push_back(i);                    s.push_back(j);                    return s;    &#125;        return s;&#125;&#125;;\n\n哈希表class Solution &#123;public:    vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123;        unordered_map&lt;int,int&gt; res;        for (int i = 0;i &lt; nums.size();i++)&#123;            auto it = res.find(target - nums[i]);  //寻找表里key是否有所需元素            if (it != res.end())&#123;                  return  &#123;it-&gt;second,i&#125;;            &#125;            res[nums[i]] = i; //没找到则把下标作为value写入表        &#125;          return &#123;&#125;;    &#125;&#125;;\n\n思路以 target - nums[i] 的方式寻找元素 x 是否存在表中，不存在则把 nums[i] 作为key值写入，以便后续查找，查找范围则是下标 i 的前向元素，若target为两个相同元素之和，此时直接返回两个下标，也不会出现重复情况\n","categories":["LeetCode"],"tags":["哈希表"]}]